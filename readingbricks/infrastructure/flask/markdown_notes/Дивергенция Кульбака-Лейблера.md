## Дивергенция Кульбака-Лейблера

Дивергенция Кульбака-Лейблера — асимметричное "расстояние" между двумя вероятностными распределениями. Из-за асимметричности и используется слово "дивергенция", а не слово "расстояние".

В случае распределений над дискретным множеством $C$ возможных классов любое вероятностное распределение можно представить в виде вектора длины $C$, сумма компонент которого равна 1. Тогда для распределений, характеризуемых векторами $p=(p_i)_{i=1}^C$ и $q=(q_i)_{i=1}^C$, дивергенция Кульбака-Лейблера равна:
$$D_{KL}\left(p \, \Vert \, q \right) = - \sum_{i=1}^C p_i \log \frac{q_i}{p_i}.$$

Смысл так введённой величины становится понятен из следующего соотношения:
$$D_{KL}\left(p \, \Vert \, q \right) = H(p, q) - H(p),$$
где $H(p, q)$ — кросс-энтропия между распределениями, описываемыми векторами $p$ и $q$, а $H(p)$ — энтропия Шеннона распределения, описываемого вектором $p$. Из выписанного равенства следует, что дивергенция Кульбака-Лейблера показывает, чему равно ожидаемое количество "лишних" бит, которые потребуется передать для описания исхода, приходящего из распределения, описываемого $p$, если для кодирования исходов была выбрана схема, оптимизированная для распределения, описываемого $q$. Также из выписанного равенства следует, что при использовании в качестве функции потерь дивергенции Кульбака-Лейблера между распределением, сконцентрированным в истинном классе объекта, и предсказанными вероятностями классов, получится то же самое, что получается при использовании логарифмической функции потерь, так как $H(p)$ не зависит от предсказанного $q$.

Свойства дивергенции Кульбака-Лейблера:

* Неотрицательна: $D_{KL}\left(p \, \Vert \, q \right) \ge 0$, причём равна 0 тогда и только тогда, когда $p = q$ (следует из неравенства Йенсена);

* С точностью до умножения на константу является предельным элементом параметрического семейства дивергенций Кресси-Рида в пределе при $\lambda \to 0$:
$$D_{KL}\left(p \, \Vert \, q \right) = -\frac{1}{2} \lim_{\lambda \to 0} \frac{2}{\lambda(\lambda + 1)} \sum_{i=1}^C p_i\left(\left(\frac{p_i}{q_i}\right)^\lambda - 1\right),$$
следует это из правила Лопиталя. К этому же параметрическому семейству с точностью до умножения на константу принадлежат расстояние Хеллингера и $\chi^2$-расстояние.
