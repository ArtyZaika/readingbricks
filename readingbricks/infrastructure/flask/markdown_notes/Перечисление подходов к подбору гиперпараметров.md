## Перечисление подходов к подбору гиперпараметров

Способы подбора гиперпараметов алгоритма машинного обучения бывают следующими:

* Перебор с экспоненциальной по числу гиперпараметров вычислительной сложностью:
    - Поиск по сетке (grid search) с кросс-валидацией относительно разбиения выборки на $k$ подвыборок;
    - Поиск по сетке с усреднением результатов $t$ кросс-валидаций относительно разбиения выборки на $k$ подвыборок;

* Перебор, подходящий и для большого числа гиперпараметров:
    - Поиск по случайному подмножеству узлов полной сетки (randomized grid search);
    - Поиск по подмножеству, составленному в соответствии с некотрым детерминированным планом эксперимента (design of experiment), которым может быть:
        - Латинский гиперкуб;
        - Оптимизированный латинский гиперкуб;
        - Последовательность Холтона;
        - Последовательность Соболя;

* Поиск оптимума в пространстве гиперпараметров на базе суррогатной модели:
    - Байесовская оптимизация предсказаний, сделанных регрессией на основе гауссовских процессов (реализована в `skopt.gp_minimize`);

* Некоторые теоретические оценки:
    - Для линейной регрессии оценка среднеквадратической ошибки при leave-one-out кросс-валидации считается в замкнутой форме без необходимости много раз настраивать веса;
    - Информационные критерии:
        - Акаике, AIC;
        - Шварца (также известен как байесовский), BIC;
    - Выбор гиперпараметров по байесовскому принципу наибольшей обоснованности (maximum evidence principle).
