{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "временные_ряды",
     "практические_приёмы"
    ]
   },
   "source": [
    "## Прогнозирование на несколько шагов вперёд ансамблями над регрессионными деревьями\n",
    "\n",
    "Регрессионные деревья и ансамбли над ними по умолчанию не предназначены для учёта временной структуры. Однако прогнозирование на несколько разных горизонтов одной и той же моделью, базирующейся на деревьях, можно осуществить следующим образом.\n",
    "\n",
    "Возьмём обучающую выборку для задачи прогнозирования на один шаг вперёд. При группировке по идентификатору объекта применим операцию сдвига целевой переменной на $k$ шагов, где $k$ принимает значения от 0 до $(h-1)$, а $h$ — желаемый горизонт прогнозирования. Получим выборку, которая в $h$ раз больше по размеру, чем исходная. Добавим в эту выборку признак, принимающий значения от 1 до $h$ и равный $(k+1)$. Этот признак можно интерпретировать как то, на сколько шагов вперёд строится прогноз. Если теперь обучить модель на таких данных, то в зависимости от поданного на стадии предсказания значения нового признака модель сможет предсказывать на любое количество шагов вперёд от 1 до $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "нейронные_сети"
    ]
   },
   "source": [
    "## Многозадачное обучение (multi-task learning)\n",
    "\n",
    "Допустим, есть вспомогательная задача, для которой имеется много размеченных данных, и есть основная задача, для которой размеченных данных существенно меньше. Также допустим, что эти две задачи работают с одними и теми же объектами, но предсказывают на них разные целевые функции. Например, во вспомогательной задаче нужно определить пол человека с портретного фото, а в основной задаче требуется определить цвет волос.\n",
    "\n",
    "В описанной ситуации можно поступить следующим образом. Построим нейронную сеть для решения вспомогательной задачи и обучим её. Затем уберём сколько-то последних слоёв получившейся сети, и вместо них поставим новые, такие что размерность выходного слоя уже соответствует основной задаче.\n",
    "\n",
    "Далее есть два варианта:\n",
    "\n",
    "1. Зафиксировать веса оставленных слоёв нейронной сети, обученной под вспомогательную задачу, и просто прогонять объекты через оставленные слои как через статичный предобработчик;\n",
    "\n",
    "2. Веса оставшихся от вспомогательной задачи слоёв обучать наравне с весами новых слоёв, то есть считать, что они просто были инициализированы по-другому, но больше отличий между ними и весами новых слоёв нет.\n",
    "\n",
    "Какой из вариантов выбрать, зависит от числа данных в основной задаче. Если острого недостатка в них нет, то второй способ, как правило, даёт более высокий результат. Первый способ, однако, быстрее, и также он менее требователен к количеству данных (а если размеченных данных совсем мало, то можно даже использовать результат прогона через оставленные обученные слои в качестве признаков для более простого метода: например, метода ближайших соседей).\n",
    "\n",
    "Новая нейронная сеть обучится лучше, чем если бы сеть с такой же архитектурой обучалась на данных для основной задачи с нуля. Дело в том, что при описанном подходе нейронная сеть будет опираться на скрытое представление, выученное по большому количеству размеченных данных оставленными слоями старой нейронной сети. Также подстройка весов под разные задачи способствует увеличению обобщающей способности. Подробности о том, почему многозадачное обучение работает, есть в разделе 3 статьи [Ruder, 2017](https://arxiv.org/pdf/1706.05098.pdf).\n",
    "\n",
    "Ещё один подход к многозадачному обучению таков: обучать нейронную сеть параллельно то под вспомогательную задачу, то под основную, при каждом переключении задачи оставляя сколько-то первых слоёв, но заменяя последние слои на то, что было ранее в задаче, к которой происходит переход."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "выбор_модели"
    ]
   },
   "source": [
    "## Перечисление подходов к подбору гиперпараметров\n",
    "\n",
    "Способы подбора гиперпараметов алгоритма машинного обучения бывают следующими:\n",
    "* Перебор с экспоненциальной по числу гиперпараметров вычислительной сложностью:\n",
    "    - Поиск по сетке (grid search) с кросс-валидацией относительно разбиения выборки на $k$ подвыборок;\n",
    "    - Поиск по сетке с усреднением результатов $t$ кросс-валидаций относительно разбиения выборки на $k$ подвыборок;\n",
    "* Перебор, подходящий и для большого числа гиперпараметров:\n",
    "    - Поиск по случайному подмножеству узлов полной сетки (randomized grid search);\n",
    "    - Поиск по подмножеству, составленному в соответствии с некотрым детерминированным планом эксперимента (design of experiment), которым может быть:\n",
    "        - Латинский гиперкуб;\n",
    "        - Оптимизированный латинский гиперкуб;\n",
    "        - Последовательность Холтона;\n",
    "        - Последовательность Соболя;\n",
    "* Поиск оптимума в пространстве гиперпараметров на базе суррогатной модели:\n",
    "    - Байесовская оптимизация предсказаний, сделанных регрессией на основе гауссовских процессов (реализована в `skopt.gp_minimize`);\n",
    "* Некоторые теоретические оценки:\n",
    "    - Для линейной регрессии оценка среднеквадратической ошибки при leave-one-out кросс-валидации считается в замкнутой форме без необходимости много раз настраивать веса;\n",
    "    - Информационные критерии:\n",
    "        - Акаике, AIC;\n",
    "        - Шварца (также известен как байесовский), BIC;\n",
    "    - Выбор гиперпараметров по байесовскому принципу наибольшей обоснованности (maximum evidence principle)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "выбор_модели"
    ]
   },
   "source": [
    "## Информационные критерии\n",
    "\n",
    "Иногда в моделях из одного и того же семейства есть параметр, регулирующий сложность. Например, в семействе полиномиальных функций сложностью можно считать максимальную допустимую степень многочлена. Довольно часто сложность можно положить равной количеству оцениваемых по данным параметров — эта формулировка, в частности, включает в себя предыдущую, ведь при оценивании многочленом степени не выше $d$ оценивается $d+1$ параметр.\n",
    "\n",
    "Модели из одного и того же семейства, отличающиеся друг от друга только сложностью, можно оценивать при помощи информационных критериев.\n",
    "\n",
    "Информационный критерий Акаике имеет вид:\n",
    "$$\\mathrm{AIC} = 2k - 2l,$$\n",
    "где $k$ — количество оценённых по данным параметров, а $l$ — значение функционала качества, достигнутое на тренировочной выборке (например, логарифм правдоподобия данных при условии того, что выборка порождается из распределения, задаваемого той моделью, которая была построена на тренировочной выборке).\n",
    "\n",
    "Байесовский информационный критерий имеет вид:\n",
    "$$\\mathrm{BIC} = \\log{(n)} \\, k - 2l,$$\n",
    "где $n$ — размер тренировочной выборки.\n",
    "\n",
    "По сути, информационные критерии представляют собой оценку качества подгонки под данные с дополнительным штрафом за сложность модели. Интуитивно говоря, чем сложнее модель, тем больше ситуаций, под которые её можно подогнать и, значит, тем менее ценны уровни качества подгонки под данные.\n",
    "\n",
    "Чем ниже значение какого-либо информационного критерия, тем более хорошей считается модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "бизнес"
    ]
   },
   "source": [
    "## Откуда может взяться недовольство заказчика машинно-обученной моделью?\n",
    "\n",
    "Любая прикладная задача моделирования имеет заказчика, неважно, внутреннего или внешнего. Когда заказчик принимает модель, он решает, устраивает ли она его. Причины недовольства заказчика бывают такие:\n",
    "\n",
    "1. Модель, и в самом деле, плохая;\n",
    "\n",
    "2. Заказчик не умеет пользоваться моделью;\n",
    "\n",
    "3. Ожидания заказчика неоправданно завышены.\n",
    "\n",
    "Какой бы ни была истинная причина, заказчик, скорее всего, решит, что реализовался первый сценарий: модель плохая. Поэтому в интересах специалиста по моделированию избежать ситуаций, когда хорошая модель попадает во второй или третий сценарий.\n",
    "\n",
    "Разберём эти два сценария подробнее.\n",
    "\n",
    "Пример сценария, когда моделью не умеют пользоваться, таков: сервис на базе модели рассылает своевременные уведомления о появлении объектов положительного класса, но люди, которым они приходят, игнорируют их. Говоря более общо, можно сказать, что возможны осложнения с интеграцией в бизнес-процессы заказчика. Чтобы упредить их возникновение, полезно задать следующие вопросы:\n",
    "* Что должно происходить с результатами работы сервиса?\n",
    "* Как именно сервис приносит конечную ценность?\n",
    "* Все ли исполнители знают и понимают ответы на два предыдущих вопроса?\n",
    "* Можно ли оперативно отслеживать сбои в исполнении действий на базе сервиса и можно ли предложить количественные метрики оценки качества исполнения таких действий?\n",
    "* Все ли признаки, использованные при обучении модели, будут доступны на стадии применения модели вовремя и в сопоставимом качестве?\n",
    "\n",
    "Что касается второго сценария, проблему завышенных ожиданий проще всего решить, ещё до старта работ по проекту согласовав метрику успеха и её целевой уровень. Сделать это можно, проведя оценку конечного эффекта от внедрения сервиса. Этот конечный эффект может быть как финансовым, то есть выражающимся в деньгах, так и каким-либо более широким (скажем, социальным), но, так или иначе, измеримым.\n",
    "\n",
    "Впрочем, бывают ситуации, когда заказчик рассуждает не в терминах конечного эффекта, а в терминах всестороннего описания зависимостей — в этом случае заказчик может потребовать, скажем, почти стопроцентную точность по положительному классу. Разумеется, модель, не способная точно описать все зависимости, тоже может быть полезна. Проиллюстрировать это заказчику можно при помощи такого сравнения: если есть лотерея, где вероятность выиграть равна $p$, стоимость участия составляет $c$, а выигрыш приносит $g$, то ответ на вопрос, рационально ли участвовать в такой лотерее, зависит не от того, насколько вероятность $p$ близка к 100%, а от того, как друг с другом соотносятся все три указанных параметра, ведь ожидаемый чистый выигрыш равен $pg - c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "нейронные_сети"
    ]
   },
   "source": [
    "## Субдискретизация (pooling)\n",
    "\n",
    "Субдискретизация (pooling) устроена так: по входу слоя проходит фильтр (filter, kernel) и каждый раз от всего, что попадает в него, берёт значение некоторой агрегирующей функции, становящееся значением в соответствующем узле (нейроне) (unit, neuron). Например, в качестве агрегирующей функции можно взять максимум — тогда речь пойдёт о субдискретизации максимумом (max pooling).\n",
    "\n",
    "Какие желаемые свойства добавляет субдискретизация максимумом?\n",
    "* Возникает устойчивость к сдвигам изображения на небольшое количество пикселей;\n",
    "* Появляется возможность реализовать следующую логику: присутствие детектируемого объекта на объединении участков зависит от того, присутствует ли объект хотя бы на одном из этих участков, а не от доли участков, на которых он присутствует."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "общая_теория"
    ]
   },
   "source": [
    "## Три фундаментальных источника ошибок в машинном обучении\n",
    "\n",
    "Оптимальный в байесовском смысле регрессор (или классификатор) — это то, что задаётся следующим формальным выражением:\n",
    "$$f_{opt} = \\arg \\min_{f \\in F} \\int_{(x, y) \\sim P_{true}(x, y)}l(f(x), y),$$\n",
    "где $F$ — множество всех возможных регрессоров (или классификаторов соответственно), $P_{true}$ — истинное совместное распределение признаков и целевой переменной, а $l$ — функция потерь, по значению регрессора (классификатора) на векторе признаков и целевой переменной на этом векторе признаков возвращающая соответствующий штраф.\n",
    "\n",
    "В реальности есть ограничения, не позволяющие найти $f_{opt}$.\n",
    "\n",
    "Во-первых, неизбежна ошибка приближения (approximation error): поиск проводится не по всему множеству возможных регрессоров (классификаторов), а лишь по какому-то подмножеству $\\overline{F} \\subset F$, например, по некому параметрическому семейству. Скажем, в случае с линейной регрессией $\\overline{F}$ — это множество всех линейных регрессоров. Как следствие, ищется уже нечто другое:\n",
    "$$\\hat{f_1} = \\arg \\min_{f \\in \\overline{F}} \\int_{(x, y) \\sim P_{true}(x, y)}l(f(x), y).$$\n",
    "Ошибка, вызываемая отличием $\\hat{f_1}$ от $f_{opt}$, и называется ошибкой приближения.\n",
    "\n",
    "Во-вторых, существует ошибка оценивания по данным (estimation error): невозможно получить истинную генеральную совокупность $P_{true}$, а вместо неё есть лишь выборка конечного размера $N$. С учётом такого ограничения задача принимает вид:\n",
    "$$\\hat{f_2} = \\arg \\min_{f \\in \\overline{F}} \\frac{1}{N} \\sum_{i=1}^{N} l(f(x_i), y_i) + \\alpha R(f),$$\n",
    "где $(x_i, y_i)$ — признаки и ответ на $i$-м объекте обучающей выборки, $R(f)$ — регуляризатор, а $\\alpha$ — коэффициент, задающий силу регуляризации. Ошибка оценивания — ошибка, вызываемая отличием $\\hat{f_2}$ от $\\hat{f_1}$.\n",
    "\n",
    "В-третьих, не всегда удаётся довести поиск минимума из предыдущего пункта до конца, и отсюда возникает ошибка оптимизации (optimization error). Если предположить, что вычислительные ресурсы ограничены и есть всего лишь $T$ итераций, то получится, что решается задача\n",
    "$$\\hat{f_3}^{(T)} = \\arg \\min_{(T); f \\in \\overline{F}} \\frac{1}{N} \\sum_{i=1}^{N} l(f(x_i), y_i) + \\alpha R(f),$$\n",
    "где запись $(T)$ под минимумом обозначает, что минимум ищется за ограниченное число шагов. По аналогии с определением предыдущих ошибок ошибка оптимизации — это ошибка, вызываемая отличием $\\hat{f_3}^{(T)}$ от $\\hat{f_2}$.\n",
    "\n",
    "Можно считать, что машинное обучение на больших данных отличается от машинного обучения на маленьких данных тем, что ошибка оптимизации начинает доминировать над ошибкой оценивания по данным.\n",
    "\n",
    "Подробности есть в статье [Bottou, Bousquet, 2007](https://papers.nips.cc/paper/3323-the-tradeoffs-of-large-scale-learning.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "подготовка_данных"
    ]
   },
   "source": [
    "## Способы автоматического обнаружения выбросов\n",
    "\n",
    "Выброс (outlier) — объект, считающийся нетипичным для генеральной совокупности, фигурирующей в задаче. Выбросы могут искажать результаты обучения модели, а также результаты оценки качества модели (что создаёт риск неправильного подбора гиперпараметров). Строго говоря, является ли какой-то объект выбросом или нет, должен определять человек, отталкиваясь от своего понимания предметной области и от знаний о том, как именно собирались данные. Тем не менее на практике автоматическое удаление выбросов тоже может существенно улучшить конечный результат.\n",
    "\n",
    "Способы обнаружения выбросов делятся на две группы в зависимости от того, на какие выбросы они реагируют:\n",
    "\n",
    "1. Способы, позволяющие выявить одномерные выбросы, то есть выбросы, являющиеся аномальными значениями какого-либо одного признака. Пример одномерного выброса: среди точек на плоскости с координатами (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (100, 6) у последней точки подозрительно большая абсцисса.\n",
    "\n",
    "2. Способы, позволяющие выявить многомерные выбросы, то есть выбросы, являющиеся аномальными объектами с точки зрения распределения данных. Пример многомерного выброса: среди точек на плоскости с координатами (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (1, 5) последняя точка лежит в стороне от прямой, на которой лежат все остальные точки, но при этом и её абсцисса, и её ордината не выбиваются из диапазона значений остальных точек.\n",
    "\n",
    "К одномерным способам относятся:\n",
    "* Стандартизированная оценка (Z-score) — из всех значений признака вычитается эмпирическое среднее этого признака, а полученные разности делятся на оценку стандартного отклонения признака; если получившееся отношение превышает 3, то объект считается выбросом. Порог 3 выбран, потому что в случае нормального распределения вероятность отклониться от среднего больше, чем на 3 стандартных отклонения, составляет 0,03% ([правило трёх сигм](https://ru.wikipedia.org/wiki/%D0%A1%D1%80%D0%B5%D0%B4%D0%BD%D0%B5%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BE%D1%82%D0%BA%D0%BB%D0%BE%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5#%D0%9F%D1%80%D0%B0%D0%B2%D0%B8%D0%BB%D0%BE_%D1%82%D1%80%D1%91%D1%85_%D1%81%D0%B8%D0%B3%D0%BC)). \n",
    "* Устойчивая стандартизированная оценка (robust Z-score) — то же самое, что и стандартизированная оценка, но теперь вычитается медиана, а не среднее, и разности делятся на средний модуль отклонения от медианы, а не на стандартное отклонение. Предпочтительнее в тех ситуациях, где выбросов достаточно много для того, чтобы они могли исказить среднее и стандартное отклонение так, что часть из них будет принята за обычные объекты.\n",
    "* Метод межквартильного размаха (interquartile range method) — берётся расстояние между 0,75-й и 0,25-й квантилями (так называемый межквартильный размах), а затем выбросами объявляются все наблюдения, отстоящие от медианы более чем на 1,5 межквартильных размаха. Численные параметры приведены в соответствии с классическим вариантом, но, разумеется, их можно поменять (например, вместо двух квартилей взять две другие квантили).\n",
    "\n",
    "К многомерным способам относятся:\n",
    "* Способы, где для каждого объекта считается расстояние Махалонобиса от него до некоторого оценённого по данным распределения, принимаемого за генеральную совокупность, а потом некой одномерной процедурой выбросами объявляются сколько-то объектов с наибольшим расстоянием Махалонобиса. Рассмотрим такой подход подробнее. Для многомерного вектора $x$ и многомерного вероятностного распределения $\\tau(\\mu, S)$ с вектором средних $\\mu$ и ковариационной матрицей $S$ \"расстоянием\" от $x$ до $\\tau(\\mu, S)$ можно положить величину:\n",
    "$$D_M(x, \\tau(\\mu, S)) = \\sqrt{(x - \\mu)^T S^{-1} (x - \\mu)},$$\n",
    "которая и называется расстоянием Махалонобиса. Интуитивно говоря, расстояние Махалонобиса отличается от евклидова расстояния между $x$ и $\\mu$ тем, что каждое направление учитывается с весом, обратно пропорциональным разбросу распределения по этому направлению. В задаче обнаружения выбросов $\\tau(\\mu, S))$ можно единожды оценить по всем имеющимся данным, если их много, или же для каждого $x$ оценивать по всем объектам кроме $x$, если данных мало.\n",
    "* Способы, где для каждого объекта считается оценка плотности генеральной совокупности в нём, а затем некой одномерной процедурой выбросами объявляются сколько-то объектов с наиболее низкой оценкой плотности. Оценку плотности можно получить, в частности, методом ядреного сглаживания (kernel density estimate). Как и в предыдущем пункте, если данных мало, то оценку ядерного сглаживания для каждого объекта лучше считать по всем объектам кроме него, а если данных много, то оценку ядерного сглаживания можно подсчитать один раз на всех объектах. Отдельно стоит отметить, что оценки ядерного сглаживания подвержены \"проклятью размерности\" и работают только в случае, когда размерность данных низкая. Если же размерность высокая, то для применения ядерного сглаживания можно предварительно снизить её, использовав PCA, t-SNE или MDS на отмасштабированных данных, однако как проводить масштабирование — нетривиальный вопрос, вносящий долю субъективности. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "нейронные_сети"
    ]
   },
   "source": [
    "## Автокодировщики с большей размерностью скрытого слоя\n",
    "\n",
    "Рассмотрим автокодировщик (autoencoder) со входным слоем размерности $l$, одним скрытым слоем размерности $h$ и выходным слоем, размерность которого по определению должна быть равна размерности входного слоя, то есть $l$. Вопрос: могут ли для чего-то пригодиться автокодировщики, где $h > l$?\n",
    "\n",
    "Без дополнительных модификаций такие автокодировщики не смогут обучаться чему-то нетривиальному, потому что всегда есть вырожденное решение: использовать лишь $l$ нейронов из $h$, чтобы просто передать вход в неизменном виде.\n",
    "\n",
    "Есть следующие способы заставить скрытый слой выучивать нетривиальное представление:\n",
    "* К ошибке восстановления, на входном векторе $x$ равной $\\Vert x - \\mathrm{autoencoder}(x)\\Vert_2$, добавить регуляризатор, подталкивающий к разреженности скрытого слоя: например, $L_1$-норму $h$-мерного вектора, получающегося из $x$ в скрытом слое;\n",
    "* Ко входу подмешивать шум, но при вычислении ошибки восстановления требовать близости к незашумлённому входу, то есть минимизировать математическое ожидание функции, на входном векторе $x$ равной $\\Vert x - \\mathrm{autoencoder}(x + \\varepsilon)\\Vert_2$, где $\\varepsilon$ — шум.\n",
    "* Каждую из компонент вектора входов с некоторой вероятностью $p$ обнулять, но при вычислении ошибки восстановления сверяться с вектором входов, где все компоненты имеют исходный вид — так автокодировщик будет побуждён выучивать взаимосвязи между признаками, позволяющие по части признаков восстановить остальные признаки. \n",
    "\n",
    "Полученный автокодировщик можно использовать в следующих целях:\n",
    "* То, что получается в скрытом слое, можно брать в качестве признакового описания объекта; такие признаки могут содержать в себе более сложные взаимодействия, чем признаки, даваемые автокодировщиком с низким $h$; пригождается это в частичном обучении (semi-supervised learning), ведь объекты без меток тоже влияют на выучиваемый способ порождать признаки;\n",
    "* До появлении пакетной нормализации и остаточного обучения была популярна \"жадная\" (послойная от входов к выходам) инициализация весов глубокой однонаправленной нейронной сети, при которой инициализируемый на данный момент слой дополнялся до автокодировщика и обучался задаче автокодировщика, где кодировалось то, что подавал на вход предыдущий слой, — стало быть, если в каком-то месте ширина нейронной сети возрастала, то требовалось обучать автокодировщик, у которого $h > l$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "постановка_задачи"
    ]
   },
   "source": [
    "## Обучение метрик (metric learning)\n",
    "\n",
    "В машинном обучении есть задача, похожая на задачу классификации, но тем не менее отличная от неё. Пусть множество рассматриваемых объектов — множество пар, элементами которого являются пары $(x_i, x_i^\\prime)$, где $x_i$ и $x_i^\\prime$ принадлежат одному и тому же пространству, а целевая переменная $y_i$ равна 1, если $x_i$ и $x_i^\\prime$ похожи друг на друга, и равна 0, если $x_i$ и $x_i^\\prime$ не похожи друг на друга. Требуется выучить отображение $f$, такое что евклидово расстояние между $f(x_i)$ и $f(x_i^\\prime)$ мало для похожих объектов и велико для непохожих объектов. Поскольку после решения задачи появляется возможность находить расстояние между объектами, а не только предсказывать, похожи ли они, данная задача отличается от задачи бинарной классификации с признаковым описанием удвоенной длины.\n",
    "\n",
    "Обучение метрик может быть полезно для решения задачи многоклассовой классификации с высоким числом классов, таких что каждый класс представлен малым числом объектов обучающей выборки. Положим все объекты одного и того же класса похожими друг на друга, а объекты разных классов отличающимися. Предсказывать классы новых объектов можно, применяя метод ближайшего соседа в пространстве, получающемся после применения отображения $f$.\n",
    "\n",
    "Для обучения метрик иногда используют функцию потерь, называемую contrastive loss:\n",
    "$$l(x_i, x_i^\\prime, f, y_i) = y_i\\Vert f(x_i) - f(x_i^\\prime)\\Vert_2 + (1 - y_i)\\max(1 - \\Vert f(x_i) - f(x_i^\\prime)\\Vert_2, 0).$$\n",
    "Эта функция потерь состоит из двух слагаемых. Первое отлично от нуля, когда взята пара похожих объектов, и это слагаемое побуждает минимизировать евклидово расстояние между тем, во что переходят похожие объекты. Второе слагаемое отлично от нуля, когда взята пара непохожих объектов, и это слагаемое побуждает отображать непохожие объекты так, чтобы расстояние между образами под действием $f$ было больше некоторого фиксированного порога.\n",
    "\n",
    "Эмпирический риск для задачи обучения с contrastive loss, как и следовало ожидать, имеет вид:\n",
    "$$E(f) = \\frac{1}{n}\\sum_{i = 1}^n  l(x_i, x_i^\\prime, f, y_i) + \\alpha R(f),$$\n",
    "где через регуляризатор $R$ и силу регуляризации $\\alpha$ можно наложить дополнительные ограничения.\n",
    "\n",
    "Если считать, что отображение $f$ задаётся умножением слева на матрицу $M$ размера $k \\times n$, то вышеуказанная функция потерь будет плоха тем, что задача её оптимизации по $M$ не является выпуклой из-за отрицательного знака перед вторым слагаемым. В таком случае берут немного другую функцию потерь, отталкивающуюся от того, что если обозначить матрицу $M^TM$ размера $n \\times n$ за $S$, то $\\Vert Mx_i - Mx_i^\\prime\\Vert_2 = (x_i - x_i^\\prime)^T S (x_i - x_i^\\prime)$:\n",
    "$$l(x_i, x_i^\\prime, S, y_i) = y_i(x_i - x_i^\\prime)^T S (x_i - x_i^\\prime) + (1 - y_i)\\max(1 - (x_i - x_i^\\prime)^T S (x_i - x_i^\\prime), 0).$$\n",
    "При минимизации эмпирического риска по матрице $S$ размера $n \\times n$ стоит учитывать ограничение, что $S$ должна быть неотрицательно определённой, иначе её нельзя было бы представить в виде $S = M^TM$. Данное ограничение является выпуклым. Однако платой за превращение задачи оптимизации в выпуклую является то, что нельзя заранее задать размерность выходного пространства, ведь ограничения на ранг матрицы $S$ не являются выпуклыми."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "постановка_задачи"
    ]
   },
   "source": [
    "## Искусственная целевая переменная\n",
    "\n",
    "Бывают ситуации, когда достоверно целевая переменная неизвестна, но её можно восстановить оценочно. Например, в задаче обнаружения подозрительного трафика, приходящего на сайт, каких-то пользоваталей можно отнести к ботам или к живым людям на основании экспертного мнения.\n",
    "\n",
    "Рассмотрим две ситуации:\n",
    "* Специалисты по предметной области написали детерминированную программу, на базе свода правил и формул вычисляющую целевую переменную по входным признакам;\n",
    "* Специалисты по предметной области не смогли составить список правил и формул, по которым можно вычислять целевую переменную, но внимательно изучили данные и разметили каждый пример вручную.\n",
    "\n",
    "Вопрос: в каких из этих двух ситуаций стоит применять машинное обучение?\n",
    "\n",
    "Ответ: только во второй. В первой ситуации построенная модель будет вести себя точно так же, как уже написанная программа, с точностью до ошибок, вызываемых нерепрезентативностью обучающей выборки, малым количеством данных и/или артефактами обучения. Иными словами, нет ничего, что позволило бы модели стать лучше, чем программа. А вот во второй ситуации модель, если хорошо обучится, станет автоматическим воплощением интуиции и знаний экспертов.\n",
    "\n",
    "Однако если немного изменить условие первой ситуации, то и в ней машинное обучение может помочь. Например, пусть программа в своих вычислениях использует также некоторый дополнительный внешний признак, такой что измерять его дорого, и который поэтому не будет доступен на стадии ежедневного применения обученной модели. Тогда можно рассчитать целевую переменную по всем признакам включая новый трудноизмеримый, а потом обучить модель предсказывать полученную целевую переменную только по признакам, которые всегда будут доступны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "постановка_задачи"
    ]
   },
   "source": [
    "## Классификация с очень большим количеством классов\n",
    "\n",
    "Пусть есть задача классификации, где различных меток много в сравнении с количеством объектов обучающей выборки (например, меток лишь в три раза меньше, чем объектов). В таком случае задача осложняется тем, что модель будет довольно редко угадывать правильную метку, и, значит, оптимизировать функции потерь, связанные с точными попаданиями, непрактично.\n",
    "\n",
    "Предположим, что задача классификации с $n$ признаками и с $q$ классами, где $q$ большое в вышеописанном смысле, решается путем поиска матрицы $W$ размера $n \\times q$, такой что близость объекта, признаковое описание которого задаётся вектором-столбцом $x$ длины $n$, к классу, закодированному вектором-столбцом $y$ длины $q$, где на позиции, номер которой равен номеру класса, стоит 1, а на остальных позициях стоят нули, вычисляется так:\n",
    "$$\\mathrm{sim}(x, y, W) = x^TWy.$$\n",
    "\n",
    "Для обучения матрицы $W$ можно использовать функции потерь из следующего параметрического семейства, зависящего от параметров $\\alpha_1$, ..., $\\alpha_q$:\n",
    "$$l(x_i, y_i, W) = \\sum_{k = 1}^{\\mathrm{rank}_W(y_i) - 1}\\alpha_k,$$\n",
    "где если верхний предел суммы равен 0, то сумма по пустому множеству индексов полагается равной нулю, а зависимость правой части от $x_i$ заложена в определении $\\mathrm{rank}_W(y_i)$. Эта величина вычисляется как порядковый номер класса $y_i$ при ранжировании классов по невозрастанию $f(y) = \\mathrm{sim}(x_i, y, W)$. В формулировке, учитывающей возможность совпадающих значений, это выглядит так:\n",
    "$$\\mathrm{rank}_W(y_i) = \\#\\!\\left\\{\\left. y \\in Q \\: \\right| \\: x_i^TWy > x_i^TWy_i\\right\\} + 1,$$\n",
    "где $Q$ — $q$-элементное множество классов, а решётка обозначает количество элементов в множестве.\n",
    "\n",
    "Некоторые известные метрики оптимизируются функциями потерь из данного семейства:\n",
    "* точность (accuracy) будет оптимизирована при $\\alpha_1 = 1$ и $\\alpha_k = 0$ для $k \\in \\{2, ..., q\\}$;\n",
    "* вероятность угадать с $m$ попыток будет оптимизирована при $\\alpha_m$ = 1 и остальных $\\alpha_k = 0$;\n",
    "* средний ранг будет оптимизирован при всех $\\alpha_k$, равных друг другу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "нейронные_сети",
     "анализ_последовательностей"
    ]
   },
   "source": [
    "## Внутреннее устройство LSTM-нейрона\n",
    "\n",
    "#### Что означает LSTM?\n",
    "\n",
    "Аббревиатура LSTM расшифровывается как Long Short-Term Memory (краткосрочная память произвольной длины). Так называется архитектура нейронной сети, часто используемая при решении задач, где объекты образуют последовательность, причём влияние некоторого объекта может распространяться на целевые переменные объектов, стоящих впереди него на произвольном расстоянии.\n",
    "\n",
    "#### Содержимое LSTM-нейрона\n",
    "\n",
    "Отличием LSTM является то, что в ней вводится специальный нейрон со сложной внутренней структурой, называемый LSTM-нейроном или LSTM-модулем (LSTM cell, LSTM unit, LSTM neuron). Рассмотрим устройство такого нейрона.\n",
    "\n",
    "Для каждого индекса $t$, которым нумеруются позиции последовательности, с LSTM-нейроном ассоциированы следующие сущности:\n",
    "* входы и выходы:\n",
    "    - вектор входов $x_t$, берущийся из последовательности и имеющий длину $d$,\n",
    "    - вектор возвращаемых нейроном выходов $y_t$, имеющий длину $h$;\n",
    "* внутреннее состояние:\n",
    "    - вектор \"памяти\" $c_t$ той же длины $h$, что и вектор выходов;\n",
    "* три вектора, называемых вентилями и имеющих ту же длину $h$, что и выход:\n",
    "    - входной вентиль (input gate), $i_t$,\n",
    "    - вентиль забвения (forget gate), $f_t$,\n",
    "    - выходной вентиль (output gate), $o_t$;\n",
    "* восемь матриц весов и четыре векторных свободных члена:\n",
    "    - $W_i$, $W_f$, $W_o$, $W_c$, их размер $h \\times d$,\n",
    "    - $U_i$, $U_f$, $U_o$, $U_c$, их размер $h \\times h$,\n",
    "    - $b_i$, $b_f$, $b_o$, $b_c$, их длина $h$.\n",
    "    \n",
    "Когда нейронная сеть уже обучена, последние двенадцать сущностей не меняются от шага к шагу, и именно поэтому индекс $t$ у них отсутствует.\n",
    "\n",
    "#### Динамика при движении по последовательности\n",
    "\n",
    "Начальные условия в позиции $t = 0$, предшествующей началу последовательности, задаются так:\n",
    "* $c_0 = 0$, $y_0 = 0$,\n",
    "* веса матриц и свободных членов как-то инициализированы, если происходит обучение, или уже обучены и зафиксированы, если речь идёт о применении,\n",
    "* чему равны вентили, неважно.\n",
    "\n",
    "При заданной последовательности $x_t$ для любой позиции $t \\ge 1$ можно рекуррентно определить значения всех сущностей, ассоциированных с LSTM-нейроном, по формулам:\n",
    "$$i_t = \\sigma(W_i x_t + U_i y_{t-1} + b_i),$$\n",
    "$$f_t = \\sigma(W_f x_t + U_f y_{t-1} + b_f),$$\n",
    "$$o_t = \\sigma(W_o x_t + U_o y_{t-1} + b_o),$$\n",
    "$$c_t = f_t \\circ c_{t-1} + i_t \\circ \\tanh (W_c x_t + U_c y_{t-1} + b_c),$$\n",
    "$$y_t = o_t \\circ \\tanh (c_t),$$\n",
    "где $\\sigma$ — сигмоидная функция активации, а $\\circ$ — операция взятия адамарова произведения (поэлементное умножение).\n",
    "\n",
    "#### Интерпретация\n",
    "\n",
    "Почему данная конструкция, после обучения являющаяся некоторой динамической системой в дискретном времени, осмысленна?\n",
    "\n",
    "Можно считать, что LSTM-нейрон в зависимости от значений вентилей способен демонстрировать различные режимы поведения (ниже 0 и 1 обозначают векторы из одних 0 или 1 соответственно):\n",
    "* при $f_t = 0$, $i_t = o_t = 1$ получается обычный рекуррентный нейрон (нейрон Элмана);\n",
    "* при $o_t = 0$, $i_t = f_t = 1$ происходит накопление входной информации (например, нейрон может работать счётчиком), а на выход информация не отдаётся;\n",
    "* при $i_t = o_t = 0$, $f_t = 1$ происходит хранение того, что в памяти, без изменений;\n",
    "* при $i_t = 0$, $f_t = o_t = 1$ происходит извлечение наружу информации, накопившейся в памяти;\n",
    "* при $i_t = f_t = 0$ происходит сбрасывание памяти.\n",
    "\n",
    "Таким образом, LSTM-нейрон обладает способностями к гибкому управлению памятью и способен проводить над ней все операции, кажущиеся необходимыми. Если данных много и закономерности в них устойчивые, то нейронная сеть с такими нейронами сможет выучить их, даже в случае отсутствия ограничения максимальной дальности влияния входов на выходы.\n",
    "\n",
    "#### Обучение\n",
    "\n",
    "Обучение LSTM-нейрона производится методом, по-английски называемым Truncated Back-Propagation Through Time, где первое слово обозначает, что в вычислениях следующие частные производные полагаются равными нулю:\n",
    "$$\\frac{\\partial i_t}{\\partial y_{t-1}} = \\frac{\\partial f_t}{\\partial y_{t-1}} = \\frac{\\partial o_t}{\\partial y_{t-1}} = \\frac{\\partial c_t}{\\partial y_{t-1}} = 0.$$\n",
    "\n",
    "#### Модификации\n",
    "\n",
    "Помимо классического LSTM-нейрона, описанного выше, существует версия, называемая LSTM с глазками (peepholes). Её отличие в том, что вентили могут обращаться к памяти нейрона (подглядывать в неё через глазки). Вводятся ещё три матрицы размера $h \\times h$, обозначаемые как $V_i$, $V_f$ и $V_o$. В рекуррентных соотношениях, задающих динамику при движении по последовательности, последние два равенства остаются неизменными, а первые три принимают вид:\n",
    "$$i_t = \\sigma(W_i x_t + U_i y_{t-1} + V_i c_{t-1} + b_i),$$\n",
    "$$f_t = \\sigma(W_f x_t + U_f y_{t-1} + V_f c_{t-1} + b_f),$$\n",
    "$$o_t = \\sigma(W_o x_t + U_o y_{t-1} + V_o c_{t} + b_o).$$\n",
    "В последнем из соотношений используется $c_t$, а не $c_{t-1}$, потому что на момент обновления значения выходного вентиля значение памяти на текущем шаге уже известно.\n",
    "\n",
    "Есть и версия LSTM с глазками, где матриц $U_i$, $U_f$, $U_o$ и $U_c$ нет (т.е. можно считать, что они тождественно нулевые)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "нейронные_сети",
     "обработка_текстов"
    ]
   },
   "source": [
    "## На пути к word2vec\n",
    "\n",
    "Помимо word2vec есть некоторые более простые способы отобразить слово в непрерывный вектор.\n",
    "\n",
    "#### Вложение на базе разбивки по коллекциям слов\n",
    "\n",
    "* Построим матрицу, где строкам соответствуют слова, столбцам — некоторые коллекции слов (например, документы или предложения), а на пересечении строки и столбца может стоять:\n",
    "    - бинарный индикатор вхождения слова в коллекцию;\n",
    "    - количество вхождений слова в коллекцию;\n",
    "    - TF-IDF;\n",
    "    - BM-25.\n",
    "* Применим к получившейся матрице какую-либо процедуру снижения размерности, такую как:\n",
    "    - метод главных компонент, PCA;\n",
    "    - многомерное шкалирование, MDS;\n",
    "    - вложение на базе случайного соседства, t-SNE.\n",
    "* Примем за векторное представление некоторого слова соответствующую этому слову строку матрицы со сниженной размерностью.\n",
    "\n",
    "#### Вложение через переходные вероятности\n",
    "\n",
    "* Пронумеруем все слова.\n",
    "* Возьмём матрицу размера $\\vert V \\vert \\times \\vert V \\vert$, где $\\vert V \\vert$ — количество слов, на пересечении $i$-й строки и $j$-го столбца которой стоит вероятность того, что сразу же после $i$-го слова в тексте встретится $j$-е слово. Казалось бы, вложением $i$-го слова можно считать $i$-ю строку такой матрицы или $i$-й столбец такой матрицы, однако у столь простого подхода есть два недостатка:\n",
    "    - Большое количество оцениваемых по данным параметров, а именно $\\vert V \\vert^2$ элементов матрицы переходных вероятностей;\n",
    "    - Размерность вектора вложения такая же, как у вектора, получаемого через one-hot encoding;\n",
    "    - Подобное представление не очень информативно, хотя и более информативно, чем представление, получаемое через one-hot encoding.\n",
    "* Попробуем получить более разумное вложение за счёт большей компактности представления. Предположим, что для некоторого фиксированного $d < \\vert V \\vert$ откуда-то даны две матрицы $W_1$ и $W_2$ размеров $d \\times \\vert V \\vert$ и $\\vert V \\vert \\times d$ соответственно, такие что матрицу переходных вероятностей удалось приблизить матрицей $W_2 W_1$. Последнее предположение формализуется и уточняется так: $\\forall i, i \\in \\{1, ..., \\vert V \\vert\\}$, после применения операции softmax к $\\vert V \\vert \\times 1$ вектору-столбцу $W_2 W_1 x_i$, где $x_i$ — вектор-столбец размера $\\vert V \\vert \\times 1$, такой что его $i$-я компонента равна 1, а остальные равны 0 (т.е. $x_i$ — one-hot представление $i$-го слова), получается вектор, близкий к вектору переходных вероятностей из $i$-го слова. В таком случае вложением слова в векторное пространство можно считать что угодно из этого списка:\n",
    "    - $i$-й столбец матрицы $W_1$;\n",
    "    - $i$-ю строку матрицы $W_2$;\n",
    "    - их полусумму (строго говоря, строку или столбец для этого нужно транспонировать);\n",
    "    - их конкатенацию (опять же, строку или столбец необходимо транспонировать).\n",
    "* Описанный в предыдущем пункте подход имеет следующие преимущества:\n",
    "    - Всего $2 d \\vert V \\vert$ обучаемых параметров;\n",
    "    - Размерность вектора вложения можно сделать маленькой;\n",
    "    - Получаются более информативные векторные представления, поскольку теперь $\\vert V \\vert \\times \\vert V \\vert$ матрица переходных вероятностей не может быть произвольной, а должна быть сводимой к виду $W_2 W_1$ с точностью до применения операции softmax к каждому столбцу указанного произведения двух матриц.\n",
    "\n",
    "#### Связь word2vec с вложением через переходные вероятности\n",
    "\n",
    "Нейронная сеть word2vec является способом найти описанные в предыдущем разделе матрицы $W_1$ и $W_2$, и в этом способе в связи с особенностями обучения нейронных сетей возникают различные специальные трюки наподобие отрицательного сэмплирования. Главное отличие в постановке задачи машинного обучения заключается в том, что в word2vec выходное слово уже не обязано идти сразу же после входного слова, а должно лишь попасть в контекст определённой ширины.  \n",
    "\n",
    "Впрочем, иногда считают, что также в word2vec вводится зависимость структуры нейронной сети от выбранного размера контекстного окна. Обозначим размер контекстного окна за $C$. Тогда:\n",
    "* в word2vec-CBoW вход имеет длину $C \\vert V \\vert$ и в скрытом слое усредняются $C$ произведений одной и той же матрицы $W_1$ со входными one-hot векторами, каждый из которых имеет длину $\\vert V \\vert$;\n",
    "* в word2vec-SkipGram выход имеет длину $C \\vert V \\vert$ и для этих $C$ блоков, представляющих вероятности попадания слова в какую-либо из позиций контекста входного слова, происходит умножение одной и той же матрицы $W_2$ на вектор скрытого слоя (то, что во всех $C$ копиях будет одно и то же вероятностное распределение, нестрашно, ведь задача не в том, чтобы предсказать контекст, а в том, чтобы обучить вложение).\n",
    "\n",
    "Так или иначе, есть и подход к word2vec, где вход и выход имеют длину $\\vert V \\vert$, то есть размеры слоёв не зависят от размера контекстного окна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "нейронные_сети",
     "обработка_текстов"
    ]
   },
   "source": [
    "## Вероятностная интерпретация word2vec\n",
    "\n",
    "Пусть есть выборка пар ($x_i$, $y_{i,c}$), где $i \\in \\{1, ..., L\\}$, $c \\in \\{1, ..., C\\}$, $C$ — как-то заданное количество слов в контексте, $x_i$ — one-hot encoded вектор слова, а $y_{i,c}$ — one-hot encoded вектор слова, встретившегося в контексте слова $x_i$ на позиции $c$.\n",
    "\n",
    "Допустим, эта выборка порождена из распределения, такого что условные вероятности выхода при условии входа имеют вид $$\\mathbb{P}(y_{i,c} \\vert x_i) = \\frac{\\exp(I(x_i)^TO(y_{i,c}))}{\\sum_{v \\in V}\\exp(I(x_i)^TO(v))},$$\n",
    "где $V$ — множество всех слов, а $I$ и $O$ — некоторые отображения из $\\vert V \\vert$-мерного в $d$-мерное пространство. Сделаем два наблюдения, касающихся выписанной формулы. Во-первых, в правой части применяется операция softmax. Во-вторых, поскольку все векторы $x_i$ и $y_{i,c}$ таковы, что в них на одной позиции стоит 1, а на всех остальных стоят 0, без ограничения общности можно считать, что $I$ и $O$ задаются умножением на матрицы размера $d \\times \\vert V \\vert$.\n",
    "\n",
    "Попытаемся найти эти матрицы, решив задачу максимизации правдоподобия имеющейся выборки:\n",
    "$$\\Pi_{i = 1}^L\\Pi_{c = 1}^C \\mathbb{P}(y_{i,c} \\vert x_i) \\rightarrow \\max_{I, O}.$$\n",
    "\n",
    "Оказывается, word2vec именно эту задачу и решает. Убедимся в этом.\n",
    "\n",
    "Неоптимизированная (слишком долго обучающаяся) word2vec принимает на вход one-hot encoded вектор слова, умножает его слева на $d \\times \\vert V \\vert$ матрицу $W_1$ (по сути, это операция взятия соответствующего слову столбца матрицы $W_1$) и делает результат вектором значений скрытого слоя, а этот вектор значений скрытого слоя умножает слева на $\\vert V \\vert \\times d$ матрицу $W_2$, чтобы получить вектор размера $\\vert V \\vert \\times 1$, после применения операции softmax к которому получаются вероятности попадания слов в контекст входного слова. Раз так, то отображением $I$, выучиваемым word2vec, является умножение слева на матрицу $W_1$, а отображением $O$ — умножение слева на транспонированную матрицу $W_2$. Выкладкой проверяется, что задача обучения неоптимизиованной word2vec с кросс-энтропией в качестве функции потерь совпадает с задачей максимизации выписанного правдоподобия.\n",
    "\n",
    "Небольшой вопрос: почему для слова с идентификатором $j$ выучивается целых два вложения, а именно $j$-й столбец матрицы $W_1$ и $j$-я строка матрицы $W_2$? Дело в том, что положить соответствующие пары весов по определению равными друг другу, чтобы при обучении они учитывались как одна переменная, нельзя, ведь тогда word2vec станет похожей на автокодировщик, и, как следствие, будет завышать вероятность того, что в контексте какого-либо слова встретится оно же само. Это видно и из вероятностной модели — скалярное произведение $I(x_i)^TO(y_{i,c})$ тем больше, чем более коллинеарны множители, а при $I \\equiv O$ это создаёт смещение в пользу $x_i$.\n",
    "\n",
    "Однако обнаруживается, что вышеописанная архитектура word2vec обучается чрезвычайно медленно, так как:\n",
    "* для вложения $\\vert V \\vert$ слов в $d$-мерное пространство требуется на каждом шаге обновлять $2 \\vert V \\vert d$ весов;\n",
    "* на каждом объекте вычисляется softmax от вектора длины $\\vert V \\vert$.\n",
    "\n",
    "Есть два способа ускорить обучение word2vec:\n",
    "* Noise Contrastive Estimation. В нём применяется отрицательное сэмплирование. Сделать его можно двумя способами:\n",
    "    - задача $\\vert V \\vert$-классовой классификации заменяется на задачу бинарной классификации, где от нейронной сети требуется по паре слов сказать, встретились ли они в одном контекстном окне или нет, а для каждого примера положительного класса, взятого из реальных текстов, при том же входном слове сэмплируется несколько выходных слов отрицательного класса, причём сэмплирование производится из эмпирического распределения слов, возведённого в степень 0,75, чтобы редкие слова выбирались чаще.\n",
    "    - рассматривается задача $\\vert V \\vert$-классовой классификации, но при обучении считаются константами все веса от входов к скрытому слою кроме весов, исходящих от текущего входного слова, и все веса от скрытого слоя к выходному слою кроме весов, ведущих к текущему выходному слову, и весов, ведущих к скольки-то другим словам отрицательно просэмплированным по процедуре, описанной в предыдущем пункте.\n",
    "* Hierarchical Softmax. В нём отображение $O$ берётся таким, что областью его определения являются не one-hot encoded векторы слов, а узлы дерева Хаффмана, листьями которого являются слова. В вероятностную модель при этом вносятся соответствующие правки:\n",
    "$$\\mathbb{P}(y_{i,c} \\vert x_i) = \\Pi_{l \\in \\mathrm{Path}(y_{i,c})} \\sigma\\!\\left(-\\mathrm{Child}(l, y_{i,c}) I(x_i)^TO(l)\\right),$$\n",
    "где $\\mathrm{Path}(y_{i,c})$ — путь от корня дерева Хаффмана до листа, соответствующего слову $y_{i,c}$, $\\sigma$ — сигмоидная функуция, а $\\mathrm{Child}(l, y_{i,c})$ равна 1, если в узле $l$ путь до вершины $y_{i,c}$ поворачивает направо, и -1 иначе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "нейронные_сети",
     "методы_оптимизации"
    ]
   },
   "source": [
    "## Метод подбора темпа обучения нейронной сети Adam\n",
    "\n",
    "В классическом варианте градиентного спуска темп обучения один и тот же для всех настраиваемых весов. Исторически одним из первых методов, где это стало не так, был AdaGrad, главный недостаток которого оказался исправлен в методе под названием RMSProp. А метод, в полном виде называющийся Adaptive Moment Estimation и обычно сокращённо называемый Adam, считается дальнейшим развитием адаптивного управления темпом обучения.\n",
    "\n",
    "Метод Adam имеет четыре гиперпараметра: $\\eta$, $\\beta_1$, $\\beta_2$ и $\\varepsilon$. Гиперпараметр $\\eta$ задаёт относительную скорость обучения (все адаптивно подобранные темпы обучения содержат его как множитель). Гиперпараметр $\\beta_1$ отвечает за сглаживание/угасание накопленного среднего градиентов, а гиперпараметр $\\beta_2$ — за сглаживание/угасание накопленного второго момента градиентов, то есть накопленного среднего их квадратов. Наконец, $\\varepsilon$ служит для численной стабильности.\n",
    "\n",
    "Положим, что по аналогии с методом RMSProp формула обновления некого параметра $\\theta$ (то есть одного из весов какого-либо слоя нейронной сети) на $t$-м шаге обучения имеет вид:\n",
    "$$\\theta_{t+1} := \\theta_t - \\frac{\\eta}{\\sqrt{v_t} + \\varepsilon}m_t,$$\n",
    "где $\\theta_t$ — текущее значение параметра $\\theta$, $\\theta_{t+1}$ — его обновлённое значение, а $m_t$ и $v_t$ — текущие значения присущих алгоритму оптимизации внутренних параметров.\n",
    "\n",
    "Эти два параметра алгоритма оптимизации $m_t$ и $v_t$ обновляются на каждом шаге по следующим правилам простого экспоненциального сглаживания:\n",
    "$$m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_{\\theta},$$\n",
    "$$v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g^2_{\\theta},$$\n",
    "где $g_{\\theta}$ — градиент для параметра нейронной сети $\\theta$ на $t$-м шаге обучения. Что касается формулы для $m_t$, экспоненциальное сглаживание в ней можно сравнить с инерцией, но только это уже инерция темпа обучения, а не инерция обновлений весов, часто используемая при обучении нейронных сетей. Что же касается формулы для $v_t$, в ней экспоненциальное сглаживание нужно не для повышения устойчивости, а для того чтобы накопленная сумма квадратов градиентов со временем могла и падать, а не только расти (главный недостаток AdaGrad как раз к тому и сводится, что там она никогда не падает).\n",
    "\n",
    "Начальными условиями, с которых начинается эволюция во времени параметров алгоритма оптимизации $m_t$ и $v_t$, являются равенства их обоих нулю:\n",
    "$$m_0 = 0,$$\n",
    "$$v_0 = 0.$$\n",
    "Раз так, то значения $m_t$ и $v_t$ при малых $t$ будут смещены в сторону нуля. Чтобы исправить это, вводят следующие скорректированные параметры:\n",
    "$$\\hat{m_t} = \\frac{m_t}{1 - \\beta_1^t},$$\n",
    "$$\\hat{v_t} = \\frac{v_t}{1 - \\beta_2^t}.$$\n",
    "\n",
    "С учётом всего вышесказанного можно выписать окончательную формулу обновления весов методом Adam:\n",
    "$$\\theta_{t+1} := \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v_t}} + \\varepsilon}\\hat{m_t}.$$\n",
    "\n",
    "Напоследок же стоит заметить, что все методы наподобие AdaGrad, RMSProp или Adam предназначены для ускорения обучения, а не для увеличения качества обученной нейронной сети. В статье [Wilson et al, 2017](https://arxiv.org/abs/1705.08292) показывается, что иногда нейронные сети, обученные ими, проигрывают нейронным сетям, обученным классическим градиентным спуском или стохастическим градиентным спуском. Таким образом, если данных мало, то стоит попробовать не только Adam, но и обычный градиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "нейронные_сети"
    ]
   },
   "source": [
    "## Декомпозиция построения и обучения нейронной сети\n",
    "\n",
    "В построении и обучении нейронных сетей есть три ключевых составляющих:\n",
    "\n",
    "1. Модель, то есть архитектура и структура нейронной сети;\n",
    "2. Функция потерь, то есть то, что оптимизируется при обучении;\n",
    "3. Оптимизатор, то есть способ по данным настроить все параметры сети.\n",
    "\n",
    "#### Модель\n",
    "\n",
    "* Сколько слоёв?\n",
    "* Какой ширины каждый из слоёв?\n",
    "* Какие нейроны (юниты) используются?\n",
    "    - обычные,\n",
    "    - с пакетной нормализацией,\n",
    "    - LSTM-модули,\n",
    "    - etc;\n",
    "* Какие связи между слоями?\n",
    "    - полные,\n",
    "    - локальные (то есть каждый нейрон связан лишь с некоторой областью предыдущего слоя),\n",
    "    - свёрточные (похожи на локальные, но веса в фильтре одинаковые для всего слоя),\n",
    "    - рекуррентные,\n",
    "    - etc;\n",
    "* Какие функции активации используются в каждом из слоёв?\n",
    "    - нет активации,\n",
    "    - сигмоида,\n",
    "    - гиперболический тангенс,\n",
    "    - ReLU и его модификации, такие как Leaky ReLU или PReLU,\n",
    "    - etc.\n",
    "* Есть ли какие-либо связанные веса (shared weights)?\n",
    "\n",
    "#### Функция потерь\n",
    "\n",
    "* Для регрессии:\n",
    "    - MSE, среднеквадратичная ошибка,\n",
    "    - MAE, средний модуль ошибки,\n",
    "    - etc.\n",
    "* Для классификации:\n",
    "    - логарифмическая функция потерь (связана с понятием кросс-энтропии, её минимизация эквивалентна минимизации дивергенции Кульбака-Лейблера),\n",
    "    - etc.\n",
    "* Для других задач:\n",
    "    - GAN loss,\n",
    "    - etc.\n",
    "\n",
    "#### Оптимизатор\n",
    "\n",
    "* На базе градиентного спуска с таким приёмом, как обратное распространение ошибок (этот приём сильно ускоряет вычисление градиента):\n",
    "    - Когда обновлять веса?\n",
    "        - После подсчёта коррекций на всех объектах обучающей выборки (классический градиентный спуск),\n",
    "        - После подсчёта коррекций на всём пакете из случайно выбранных объектов обучающей выборки (пакетный градиентный спуск),\n",
    "        - После подсчёта коррекций на каждом отдельно взятом объекте (стохастический градиентный спуск).\n",
    "    - Какой темп обучения (learning rate) выбрать?\n",
    "        - Постоянный,\n",
    "        - С расписанием, то есть в виде заранее заданной невозрастающей функции от числа шагов,\n",
    "        - Адаптивный:\n",
    "            - AdaGrad,\n",
    "            - RMSProp,\n",
    "            - Adam.\n",
    "    - Какую инерцию (momentum) обновлений весов выбрать?\n",
    "        - никакую,\n",
    "        - обычную,\n",
    "        - инерцию Нестерова.\n",
    "    - Как инициализировать веса каждого из слоёв перед началом обучения?\n",
    "        - Случайно породить $I \\times O$ весов, где $I$ — размер входа слоя, а $O$ — размер выхода слоя:\n",
    "            - Из гауссовского распределения с нулевым средним и дисперсией:\n",
    "                - 0.01 (или ещё меньше, если всё равно обучение не идёт),\n",
    "                - $2 / (I + O)$ (Glorot Normal Initialization),\n",
    "                - $1/I$ (часто используется для функции активации $\\tanh$),\n",
    "                - $2/I$ (He Normal Initialization, часто используется для функции активации ReLU);\n",
    "            - Из равномерного распределения на отрезке $[-a, a]$, где $a$ равно:\n",
    "                - $\\sqrt{6 / (I + O)}$ (Glorot Uniform Initialization),\n",
    "                - $\\sqrt{3 / I}$ (LeCun Uniform Initialization).\n",
    "        - Жадно послойно предобучить с дополнением до автокодировщика.\n",
    "    - Какие техники регуляризации использовать?\n",
    "        - $L_1$-регуляризация (приводит к отбору весов),\n",
    "        - $L_2$-регуляризация (приводит к затуханию весов),\n",
    "        - дропаут,\n",
    "        - подмешивание шума.\n",
    "    - Использовать ли раннюю остановку, отталкивающуюся от оценки качества на отложенной выборке?\n",
    "* На базе генетических алгоритмов (не мэйнстрим в обучении нейронных сетей)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "активное_обучение",
     "постановка_задачи"
    ]
   },
   "source": [
    "## Оценивание дисперсии целевой переменной\n",
    "\n",
    "Если функцией потерь, с которой обучается регрессор, является среднеквадратичная ошибка (MSE), то регрессор будет пытаться предсказать условное среднее целевой переменной при условии признаков. Если взять средний модуль ошибки (MAE), то тогда получится оценка условной медианы целевой переменной при условии признаков. Оценка условной дисперсии целевой переменной при условии признаков тоже может быть получена, хотя это и не достигается за счёт выбора подходящей функции потерь. Нужна же оценка условной дисперсии, например, тогда, когда есть возможность дополнительно запрашивать примеры в обучающую выборку — из областей признакового пространства, где дисперсия выше, хочется иметь больше примеров, чем из областей признакового пространства, где дисперсия ниже.\n",
    "\n",
    "Для получения оценки условной дисперсии применим следующий эвристический подход:\n",
    "* С MSE в качестве функции потерь обучим модель с исходной целевой переменной;\n",
    "* С MSE в качестве функции потерь обучим модель, для которой целевой переменной является квадрат исходной целевой переменной;\n",
    "* Предсказанием дисперсии на некотором объекте назовём разность предсказания второй модели и предсказания первой модели, если эта разность больше 0, и 0 иначе.\n",
    "\n",
    "Описанный подход опирается на определение дисперсии как разности математического ожидания квадрата и квадрата математического ожидания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "постановка_задачи",
     "практические_приёмы"
    ]
   },
   "source": [
    "## Перенос модели из одной среды в другую\n",
    "\n",
    "Предположим, что на некотором наборе признаков уже обучена модель, но все данные, из которых была составлена обучающая выборка, приходили из одной среды, а теперь хочется решать аналогичную задачу для объектов, приходящих из другой среды, где доступны только признаковые описания, но не целевые переменные.\n",
    "\n",
    "Примеры подобных ситуаций таковы:\n",
    "* Для решения задачи кредитного скоринга банк, работавший в некотором регионе, собрал достаточно размеченных примеров с жителями этого региона. Теперь банк хочет открыть отделение в другом регионе, однако там за короткое время можно собрать только заявки на кредит с признаками, но без целевой переменной, ведь для того, чтобы узнать, будет ли кредит возвращён, нужно ждать несколько лет.\n",
    "* Мобильное приложение с моделью монетизации freemium (установка и базовое использование бесплатны, платны дополнительные возможности), долгое время выпускавшееся лишь под одну платформу, получило версию под другую платформу. Маркетологи хотят получать предсказание будущих поступлений от пользователей, привлекаемых в версию под новую платформу той или иной рекламной кампанией. Прямо сейчас доступны только параметры аудиторий и рекламных кампаний, но не конечный результ, ведь для его измерения необходимо ждать время, равное некой высокой квантили срока активности пользователя в приложении.\n",
    "\n",
    "До тех пор, пока в новой среде не собрано достаточное количество размеченных данных, можно задействовать урезанную версию модели, обученную на данных из старой среды. Строится она так:\n",
    "* Признаковые описания объектов из обеих сред вертикально конкатенируются, а новой целевой переменной становится бинарная переменная, равная 0, если объект пришёл из одной среды, и 1, если из другой.\n",
    "* Обучается классификатор примерно той же природы, что и исходная модель, и смотрится, какие признаки обладают для него наибольшей важностью.\n",
    "* Ищется подмножество признаков, такое что на нём классификатор не может показать хорошие метрики качества. Это подмножество признаков — подмножество таких признаков, что они с точки зрения моделей, похожих на выбранный классификатор, в совокупности выглядят одинаково в обеих средах.\n",
    "* На отобранном подмножестве признаков только на объектах из старой среды обучается модель для исходной задачи, и именно эту модель можно использовать для предсказаний на объектах из новой среды.\n",
    "\n",
    "Описанный приём позволяет избежать ошибок экстраполяции, связанных с тем, что модель применяется в ранее не виденных ей областях признакового пространства. В то же время использование лишь части признаков приводит к некоторому снижению качества модели. Стало быть, нужно найти оптимальный баланс между качеством модели и степенью различия между средами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "нейронные_сети"
    ]
   },
   "source": [
    "## Пакетная нормализация\n",
    "\n",
    "Слои нейронов с пакетной нормализацией имеют то преимущество перед обычными слоями, что обучаются быстрее, а ещё им сопутствует некоторая дополнительная регуляризация, благодаря которой порой не нужен дропаут. Правда, обучаться слои с пакетной нормализацией могут только пакетным градиентным спуском.\n",
    "\n",
    "Везде далее речь пойдёт о нейроне слоя с пакетной нормализацией, а не о целом слое, хотя то же самое можно сформулировать и в терминах слоя.\n",
    "\n",
    "При пакетной нормализации помимо обычных весов с каждым нейроном ассоциированы следующие дополнительные сущности:\n",
    "* Два скаляра, обучаемых пакетным градиентных спуском:\n",
    "    - $\\gamma$, скаляр перемасштабирования, инициализируется 1,\n",
    "    - $\\beta$, скаляр сдвига, инициализируется 0;\n",
    "* Два скаляра, существующих только во время обучения:\n",
    "    - $\\mu_\\mathrm{batch}$, среднее по текущему пакету от значений, подаваемых непосредственно в функцию активации нейрона (то есть от значений, возникающих после умножения входов на соответствующие веса, но до взятия функции активации от получившейся суммы),\n",
    "    - $\\sigma_\\mathrm{batch}$, среднеквадратичное отклонение значений, подаваемых непосредственно в функцию активации нейрона, подсчитанное по текущему пакету;\n",
    "* Два скаляра, арифметическими операциями обновляемые на каждом пакете во время обучения и остающиеся константами во время применения, нужны они только на стадии применения:\n",
    "    - $\\mu_\\mathrm{cum}$, экспоненциальное среднее от средних по пакетам значений, подаваемых непосредственно в функцию активации нейрона,\n",
    "    - $\\sigma_\\mathrm{cum}$, экспоненциальное среднее от внутрипакетных среднеквадратичных отклонений значений, подаваемых непосредственно в функцию активации нейрона.\n",
    "    \n",
    "К числу гиперпараметров пакетная нормализация добавляет только коэффициент сглаживания $\\alpha$ для подсчёта экспоненциальных средних (или несколько таких коэффициентов для разных слоёв и отдельно для средних и среднеквадратичных отклонений).\n",
    "   \n",
    "Идея, стоящая за пакетной нормализацией, восходит к тому, что в машинном обучении бывает полезно центрировать данные и делать их дисперсию единичной. В контексте нейронных сетей это особенно актуально, если функцией активации является сигмоида или гиперболический тангенс, потому что у них градиенты заметно отличаются от нуля лишь в окрестности нуля. Также в случае глубоких нейронных сетей вычитание среднего и деление на дисперсию не могут быть частью предобработки данных, а должны быть частью процесса обучения, потому что до слоёв, расположенных далеко от входных, эффект от разовой предобработки может и не дойти.\n",
    "\n",
    "Обучение нейрона, с которым на текущий момент ассоциирован вектор-строка весов $w$ и которому в пакете подаются векторы-столбцы $x_i$, где $i$ принимает значения от 1 до размера пакета, выглядит так:\n",
    "* Вычислить все $u_i = wx_i$ (свободный член отсутствует, потому что его он избыточен в случае пакетной нормализации, ведь его заменяет $\\beta$);\n",
    "* Вычислить $\\mu_\\mathrm{batch}$ как среднее $u_i$ и вычислить $\\sigma_\\mathrm{batch}$ как среднеквадратичное отклонение $u_i$;\n",
    "* Вычислить нормализованные значения $v_i = (u_i - \\mu_\\mathrm{batch}) \\: / \\: (\\sigma_\\mathrm{batch} + \\varepsilon)$, где $\\varepsilon$ — некоторая малая константа, позволяющая избежать проблем с делением на ноль;\n",
    "* Обновить значения $\\mu_\\mathrm{cum}$ и $\\sigma_\\mathrm{cum}$ по правилу простого экспоненциального сглаживания:\n",
    "$$\\mu_\\mathrm{cum} := \\alpha\\mu_\\mathrm{cum} + (1-\\alpha)\\mu_\\mathrm{batch},$$\n",
    "$$\\sigma_\\mathrm{cum} := \\alpha\\sigma_\\mathrm{cum} + (1-\\alpha)\\sigma_\\mathrm{batch};$$\n",
    "* Вычислить значения функции активации $f_\\mathrm{activ}(\\gamma v_i + \\beta)$ и передать каждое из них как вход для следующего слоя на соответствующем ($i$-м) объекте батча;\n",
    "* При обновлении параметров нейронной сети методом обратного распространения ошибок также считать градиенты по $\\gamma$ и $\\beta$, чтобы градиентный спуск сам мог решить, какими примерно должны быть средние и дисперсии, ведь это влияет на то, какие участки нелинейности функции активации задействованы.\n",
    "\n",
    "На стадии применения для нормализации всегда используются $\\mu_\\mathrm{cum}$ и $\\sigma_\\mathrm{cum}$, а $\\gamma$ и $\\beta$ полагаются константами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "нейронные_сети",
     "постановка_задачи",
     "теория_информации"
    ]
   },
   "source": [
    "## Логарифмическая функция потерь (log loss) и энтропия Шеннона\n",
    "\n",
    "Логарифмическая функция потерь имеет вид:\n",
    "$$\\mathrm{log\\_loss}\\left(y, \\hat{P}\\right) = -\\frac{1}{N}\\sum_{i = 1}^N\\sum_{j = 1}^C [y_i = j] \\, \\log \\hat{P}_{ij},$$\n",
    "где $N$ — количество объектов, $C$ — количество классов, $y$ — вектор длины $N$, такой что его $i$-я компонента $y_i$ равна верному ответу на $i$-м объекте выборки, $\\hat{P}$ — матрица размера $N \\times C$, такая что на пересечении $i$-й строки и $j$-го столбца стоит предсказанная вероятность принадлежности $i$-го объекта к $j$-му классу, а, наконец, квадратные скобки даны в нотации Айверсона, то есть выражение с ними равно 1, если то, что в скобках, верно, и равно 0, если то, что в скобках, неверно.\n",
    "\n",
    "Логарифмическая функция потерь имеет интерпретацию, восходящую к теории информации. Чтобы понять, какие идеи стоят за логарифмической функцией потерь, обратимся к понятию энтропии Шеннона. Энтропия Шеннона — функционал на вероятностных распределениях. Поскольку речь идёт о $C$-классовой классификации, определим энтропию Шеннона только на вероятностных распределениях на множестве $C$ классов, хотя на самом деле она определена и для непрерывных распределений:\n",
    "$$H(p) = - \\sum_{i = 1}^C p_i \\log_2{p_i},$$\n",
    "где $p = (p_i)_{i=1}^C$ — вектор длины $C$, такой что его $i$-я компонента $p_i$ равна вероятности того, что просэмплированный из генеральной совокупности объект принадлежит к $i$-му классу.\n",
    "\n",
    "Какой смысл в так определённой величине? Короткий ответ: она сообщает, чему равно математическое ожидание (относительно генеральной совокупности) количества бит информации, получаемой при измерении класса одного случайного объекта. Например, если все классы кроме одного имеют нулевую вероятность, то $H(p) = 0$, ведь никакой информации в измерении класса нет: и без измерений известно, что может быть только один класс.\n",
    "\n",
    "Из короткого ответа непонятно, почему энтропия Шеннона, и впрямь, является ожидаемым количеством бит информации, даваемым замером класса на одном случайном объекте. Чтобы углубиться в это, придётся немного формализовать задачу. Допустим, метку каждого класса представили в виде последовательности нулей и единиц (т.е. последовательности бит) так, что у разных классов разные метки. При вышеописанной кодировке введём $l$ как вектор длины $C$, $l = (l_i)_{i=1}^C$, $i$-я компонента которого $l_i$ равна длине последовательности нулей и единиц, кодирующей метку $i$-го класса. Задача ставится как задача минимизации по возможным способам закодировать метки классов (так, чтобы разные классы имели разные метки) следующего функционала, являющегося математическим ожиданием длины последовательности, представляющей класс случайного объекта:\n",
    "$$L = \\sum_{i = 1}^C p_i l_i.$$\n",
    "Шеннон показал, что оптимальное значение $L_{opt}$ не может быть меньше, чем $H(p)$. Более того, существуют схемы, позволяющие приблизиться к этому теоретическому минимуму, а именно коды Хаффмана и коды Шеннона-Фано. Таким образом, становится понятно, почему $H(p)$ можно интерпретировать как ожидаемое количество бит информации, ведь в вышеописанной тракторвке это ожидаемая длина битового представления метки класса при оптимальном кодировании меток.\n",
    "\n",
    "Чтобы понять, как логарифмическая функция потерь связана с энтропией Шеннона, введём понятие кросс-энтропии между двумя задаваемыми векторами $p$ и $q$ вероятностными распределениями на метках классов:\n",
    "$$H(p, q) = - \\sum_{i = 1}^C p_i \\log_2{q_i}.$$\n",
    "Эта величина может восприниматься следующим образом. Допустим, вектор $p$ содержит истинные вероятности классов, но при выборе способа закодировать метки классов думали, что истинные вероятности классов задаются вектором $q$, так что и кодирование получилось оптимальным для $q$. В таком случае $H(p, q)$ задаёт ожидаемое количество бит информации, которую потребуется передать, чтобы с указанным оптимальным для $q$ кодированием сообщить метку класса объекта, пришедшего из распределения, характеризуемого $p$. Только что кросс-энтропия $H(p, q)$ была описана с точки зрения разрастания количества бит, которое потребуется передать, но есть и взгляд с точки зрения потери информации: если разрешено передать лишь столько бит, сколько ровно хватило бы при оптимальном для $p$ кодировании, то при оптимальном для $q$ кодировании часть информации придётся потерять.\n",
    "\n",
    "Так вот, логарифмическая функция потерь — средняя по выборке кросс-энтропия между распределением, сконцентрированным в истинном классе объекта, и распределением, задаваемым предсказанными для этого объекта вероятностями классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "теория_информации"
    ]
   },
   "source": [
    "## Дивергенция Кульбака-Лейблера\n",
    "\n",
    "Дивергенция Кульбака-Лейблера — асимметричное \"расстояние\" между двумя вероятностными распределениями. Из-за асимметричности и используется слово \"дивергенция\", а не слово \"расстояние\".\n",
    "\n",
    "В случае распределений над дискретным множеством $C$ возможных классов любое вероятностное распределение можно представить в виде вектора длины $C$, сумма компонент которого равна 1. Тогда для распределений, характеризуемых векторами $p=(p_i)_{i=1}^C$ и $q=(q_i)_{i=1}^C$, дивергенция Кульбака-Лейблера равна:\n",
    "$$D_{KL}\\left(p \\, \\Vert \\, q \\right) = - \\sum_{i=1}^C p_i \\log \\frac{q_i}{p_i}.$$\n",
    "\n",
    "Смысл так введённой величины становится понятен из следующего соотношения:\n",
    "$$D_{KL}\\left(p \\, \\Vert \\, q \\right) = H(p, q) - H(p),$$\n",
    "где $H(p, q)$ — кросс-энтропия между распределениями, описываемыми векторами $p$ и $q$, а $H(p)$ — энтропия Шеннона распределения, описываемого вектором $p$. Из выписанного равенства следует, что дивергенция Кульбака-Лейблера показывает, чему равно ожидаемое количество \"лишних\" бит, которые потребуется передать для описания исхода, приходящего из распределения, описываемого $p$, если для кодирования исходов была выбрана схема, оптимизированная для распределения, описываемого $q$. Также из выписанного равенства следует, что при использовании в качестве функции потерь дивергенции Кульбака-Лейблера между распределением, сконцентрированным в истинном классе объекта, и предсказанными вероятностями классов, получится то же самое, что получается при использовании логарифмической функции потерь, так как $H(p)$ не зависит от предсказанного $q$.\n",
    "\n",
    "Свойства дивергенции Кульбака-Лейблера:\n",
    "* Неотрицательна: $D_{KL}\\left(p \\, \\Vert \\, q \\right) \\ge 0$, причём равна 0 тогда и только тогда, когда $p = q$ (следует из неравенства Йенсена);\n",
    "* С точностью до умножения на константу является предельным элементом параметрического семейства дивергенций Кресси-Рида в пределе при $\\lambda \\to 0$:\n",
    "$$D_{KL}\\left(p \\, \\Vert \\, q \\right) = -\\frac{1}{2} \\lim_{\\lambda \\to 0} \\frac{2}{\\lambda(\\lambda + 1)} \\sum_{i=1}^C p_i\\left(\\left(\\frac{p_i}{q_i}\\right)^\\lambda - 1\\right),$$\n",
    "следует это из правила Лопиталя. К этому же параметрическому семейству с точностью до умножения на константу принадлежат расстояние Хеллингера и $\\chi^2$-расстояние."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "байесовские_методы",
     "статистический_вывод"
    ]
   },
   "source": [
    "## Общий взгляд на EM-алгоритм\n",
    "\n",
    "#### Введение\n",
    "\n",
    "В задаче кластеризации EM-алгоритм может использоваться для разделения смеси гауссовских распределений. Он имеет ряд преимуществ перед методом K-средних. Во-первых, вместо бинарных индикаторов принадлежности к кластеру вводятся нечёткие степени принадлежности к кластеру. Во-вторых, ковариационные матрицы гауссиан не обязаны быть единичными (как это неявно предполагается при измерении евклидова расстояния до центров кластеров в алгоритме K-средних)— для отсутствия вычислительной неустойчивости достаточно, чтобы они были диагональными, хотя есть и версии с более слабыми ограничениями.\n",
    "\n",
    "На самом же деле, EM-алгоритм имеет более общий вид, чем алгоритм для разделения смеси гауссовских распределений. Это алгоритм, позволяющий делать две вещи:\n",
    "* оценивать параметры распределений тогда, когда часть переменных относится к ненаблюдаемым;\n",
    "* решать задачу статистического вывода (statistical inference), то есть задачу оценивания значений ненаблюдаемых признаков объекта по его значениям наблюдаемых признаков.\n",
    "\n",
    "Более того, EM-алгоритм может применяться и к выборкам, где векторы объектов не являются независимыми одинаково распределёнными: например, он может применяться к последовательностям (таким как марковские цепи).\n",
    "\n",
    "#### Постановка задачи\n",
    "\n",
    "Формализуем постановку задачи следующим образом.\n",
    "\n",
    "Пусть есть следующие сущности:\n",
    "* $X$ — $(l \\times n)$-матрица наблюдаемых переменных, где $l$ — количество объектов в выборке, а $n$ — количество наблюдаемых признаков;\n",
    "* $Z$ — $(l \\times h)$-матрица скрытых переменных, где $h$ — количество скрытых признаков, а $l$ то же самое, что и в матрице $X$. Для получения полных признаковых описаний объектов выборки матрицу $Z$ нужно соединить с матрицей $X$ боковой конкатенацией;\n",
    "* $\\theta$ — неизвестный вектор параметров вероятностного распределения, породившего выборку; этот вектор требуется оценить по данным; в обычной постановке это детерминированный вектор, в байесовской же постановке (рассматриваемой лишь в самом конце заметки) это случайный вектор со своим собственным распределением.\n",
    "\n",
    "Про функцию плотности матрицы наблюдаемых переменных пусть будет известно, что она допускает представление в виде:\n",
    "$$p(X \\, \\vert \\, \\theta) = \\int p(X, Z \\, \\vert \\, \\theta) dZ,$$\n",
    "где $p(X, Z \\, \\vert \\, \\theta)$ дана в аналитическом виде для любой длины $l$ матриц $X$ и $Z$.\n",
    "\n",
    "Тут уместно пояснить, почему выше используются матрицы $X$ и $Z$ вместо векторов-строк $x$ и $z$, соответствующих какому-либо одному объекту. Дело в том, что различные строки матриц $X$ или $Z$ могут не быть независимыми друг от друга, так что в общем случае функцию плотности нужно брать не от отдельных объектов выборки, а от всей выборки сразу.\n",
    "\n",
    "Задача заключается в том, чтобы методом максимального правдоподобия найти оценку для $\\theta$, имея обучающую выборку $X$, составленную только из наблюдаемых переменных: \n",
    "$$\\hat{\\theta} = \\arg\\max_\\theta \\log p(X \\, \\vert \\, \\theta).$$\n",
    "Имея оценку $\\hat{\\theta}$, можно по матрице с наблюдаемой частью признакового описания объектов $X$ выводить матрицу ненаблюдаемой части признакового описания этих объектов $Z$ следующим образом:\n",
    "$$\\hat{Z} = \\arg\\max_Z p(X, Z \\, \\vert \\, \\hat{\\theta}).$$\n",
    "\n",
    "#### Пример частной постановки\n",
    "\n",
    "Задача разделения смеси гауссовских распределений является частным случаем описанной задачи, получающимся из неё, если положить, что:\n",
    "* $X$ — $(l \\times n)$-матрица наблюдаемых признаков объектов;\n",
    "* $Z$ — $(l \\times 1)$-матрица (т.е. вектор-столбец) с дискретной скрытой переменной, задающей идентификатор (номер) компоненты смеси, откуда был порождён объект;\n",
    "* $\\theta$ — неизвестный вектор, составленный из:\n",
    "    - вероятностей компонент смеси $p(z)$, где $z$ — скалярный идентификатор компоненты смеси,\n",
    "    - центров гауссовских распределений $(\\mu_z)_{z=1}^m$, где $m$ — количество компонент смеси,\n",
    "    - ковариационных матриц гауссовских распределений $(S_z)_{z=1}^m$, развёрнутых из двумерного в одномерный вид, чтобы стать компонентами вектора $\\theta$.\n",
    "\n",
    "Чтобы показать, что задача разделения смеси гауссовских распределений является частным случаем поставленной задачи, необходимо и достаточно убедиться, что $p(X, Z \\, \\vert \\, \\theta)$ дана в аналитическом виде. Поскольку в задаче разделения смеси гауссовских распределений объекты являются независимыми одинаково распределёнными, верно, что:\n",
    "$$p(X, Z  \\, \\vert \\, \\theta) = \\Pi_{i=1}^l p(x_{i\\dot{}}, z_{i\\dot{}}  \\, \\vert \\, \\theta),$$\n",
    "где $x_{i\\dot{}}$ обозначает $i$-ю строку матрицы $X$, а $z_{i\\dot{}}$ обозначает $i$-ю строку матрицы $Z$. Для векторов-строк $x_{i\\dot{}}$ и $z_{i\\dot{}}$ (т.е. матриц размера $1 \\times n$ и $1 \\times 1$ соответственно) плотность имеет следующий вид: \n",
    "$$p(x_{i\\dot{}}, z_{i\\dot{}} \\, \\vert \\, \\theta) = p(z_{i\\dot{}}) \\mathcal{N}_{\\mu_{z_{i\\dot{}}}, S_{z_{i\\dot{}}}}(x_{i\\dot{}}),$$\n",
    "где $z_{i\\dot{}}$ — как уже упоминалось, скалярный идентификатор компоненты смеси, $\\mathcal{N}_{\\mu_{z_{i\\dot{}}}, S_{z_{i\\dot{}}}}(x_{i\\dot{}})$ — плотность гауссовского распределения с соответствующими параметрами в точке с координатами $x_{i\\dot{}}$, а $p(z_{i\\dot{}})$, $\\mu_{z_{i\\dot{}}}$ и $S_{z_{i\\dot{}}}$ извлечены из $\\theta$. Подстановкой этого равенства в предыдущее и получается аналитический вид для $p(X, Z  \\, \\vert \\, \\theta)$.\n",
    "\n",
    "#### Обозначения\n",
    "\n",
    "Обозначим за $q(Z)$ плотность некоторого (не обязательно известного) вероятностного распределения матрицы $Z$. В дальнейшем будет считаться, что эта плотность приближает плотность апостериорной вероятности $p(Z \\, \\vert \\, X, \\theta)$. Например, в задаче разделения смеси гауссовских распределений $q(Z)$ хранит информацию о сформировавшихся к текущей итерации EM-алгоритма нечётких степенях принадлежности к кластерам.\n",
    "\n",
    "Наконец, для определённости в том, использовать ли знак интеграла или знак суммы, будем считать, что $Z$ является матрицей с элементами из $\\mathbb{R}$. Если элементы $Z$ дискретны, то интегралы заменятся на суммы, но содержательно ничего не изменится.\n",
    "\n",
    "#### Приём из вариационного вывода\n",
    "\n",
    "Для решения общей задачи предпримем следующие шаги, на каждом из которых будем преобразовывать логарифм правдоподобия наблюдаемой выборки:\n",
    "* $\\log p(X \\, \\vert \\, \\theta) = \\int q(Z) \\log p(X \\, \\vert \\, \\theta) dZ$, потому что левая часть не зависит от $Z$, а справа её просто внесли как константу в интеграл, равный 1;\n",
    "* правую часть только что выписанного равенства представим в виде $\\int q(Z) \\log \\frac{p(X, Z \\, \\vert \\, \\theta)}{p(Z \\, \\vert \\, X, \\theta)} dZ$ — сделать это можно по теореме Байеса;\n",
    "* домножим выражение под логарифмом на единицу, домножив числитель и знаменатель на одно и то же: $\\int q(Z) \\log \\frac{p(X, Z \\, \\vert \\, \\theta) \\, q(Z)}{p(Z \\, \\vert \\, X, \\theta) \\, q(Z)} dZ$;\n",
    "* воспользуемся тем, что логарифм произведения равен сумме логарифмов, а множители сгруппируем крест-накрест: $\\int q(Z) \\log \\frac{p(X, Z \\, \\vert \\, \\theta)}{q(Z)} dZ + \\int q(Z) \\log \\frac{q(Z)}{p(Z \\, \\vert \\, X, \\theta)} dZ$.\n",
    "\n",
    "Первое слагаемое обозначим за $\\mathcal{L}(q, \\theta)$:\n",
    "$$\\mathcal{L}(q, \\theta) = \\int q(Z) \\log \\frac{p(X, Z \\, \\vert \\, \\theta)}{q(Z)} dZ.$$\n",
    "Отметим, что в правой части присутствует $X$, но он не выписан как аргумент, от которого зависит $\\mathcal{L}(q, \\theta)$. Опустить $X$ можно по следующей причине: это уже заданная константная матрица пронаблюдавшихся значений. Таким образом, $\\mathcal{L}(q, \\theta)$ является функционалом, зависящим от функции плотности $q$ и вектора $\\theta$.\n",
    "\n",
    "Кроме того заметим, что второе слагаемое в получившемся на последнем шаге выражении равно дивергенции Кульбака-Лейблера между произвольным распределением $q(Z)$ и распределением $p(Z \\, \\vert \\, X, \\theta)$, вид которого можно получить из известного по условию распределения $p(X, Z \\, \\vert \\, \\theta)$:\n",
    "$$D_{KL}(q(Z) \\, \\Vert \\, p(Z \\, \\vert \\, X, \\theta)) = \\int q(Z) \\log \\frac{q(Z)}{p(Z \\, \\vert \\, X, \\theta)} dZ.$$\n",
    "\n",
    "Итак, путём вышеописанных преобразований было получено, что:\n",
    "$$\\log p(X \\, \\vert \\, \\theta) = \\mathcal{L}(q, \\theta) + D_{KL}(q(Z) \\, \\Vert \\, p(Z \\, \\vert \\, X, \\theta)).$$\n",
    "Второе слагаемое правой части неотрицательно в силу соответствующего свойства дивергенции Кульбака-Лейблера. Из этих соображений первое слагаемое называют нижней вариационной оценкой для $\\log p(X \\, \\vert \\, \\theta)$.\n",
    "\n",
    "#### Описание EM-алгоритма\n",
    "\n",
    "Теперь всё готово, для того чтобы описать EM-алгоритм, пошагово максимизирующий по $\\theta$ прологарифмированное правдоподобие $\\log p(X \\, \\vert \\, \\theta)$:\n",
    "* E-шаг: при фиксированном $\\theta = \\theta^{(n)}$ решается задача $\\mathcal{L}(q, \\theta^{(n)}) \\to \\max_{q \\in Q}$, где $Q$ — некоторое заранее выбранное множество вероятностных распределений. Для получения общего представления о том, как проводится такая максимизация, рассмотрим случай, когда $Q$ — множество всех вероятностных распределений. В этом случае делаются точные E-шаги, а решение оптимизационной задачи получается тогда, когда обнуляется дивергенция Кульбака-Лейблера, поскольку $\\mathcal{L}(q, \\theta^{(n)})$ не может быть больше $\\log p(X \\, \\vert \\, \\theta^{(n)})$, в рамках текущего шага являющегося известной константой. Значит, решением задачи максимизации является распределение $q^{(n+1)}(Z) = p(Z \\, \\vert \\, X, \\theta^{(n)}) = \\frac{p(X, Z \\, \\vert \\, \\theta^{(n)})}{\\int p(X, Z \\, \\vert \\, \\theta^{(n)}) dZ}$, где правая часть (с точностью до взятия интеграла из знаменателя) известна, потому что $X$ известен, $\\theta^{(n)}$ известен и по предоположению, сделанному в формулировке задачи, известен аналитический вид $p(X, Z \\, \\vert \\, \\theta)$;\n",
    "* М-шаг: при фиксированном $q = q^{(n)}$ решается задача $\\mathcal{L}(q^{(n)}, \\theta) \\to \\max_{\\theta}$. Поскольку логарифм частного равен разности логарифмов делимого и делителя, а распределение $q^{(n)}$ зафиксировано, задача эквивалентна задаче $\\mathbb{E}_{q^{(n)}} \\log p(X, Z \\, \\vert \\, \\theta) \\to \\max_{\\theta}$, где матрица $Z$ случайна и именно по её распределению берётся математическое ожидание. Вообще говоря, выписанная оптимизационная задача может быть многоэкстремальной, но если $Q$ — экспоненциальный класс распределений, то задача выпуклая (максимизируется вогнутая функция).\n",
    "\n",
    "#### Различные версии EM-алгоритма\n",
    "\n",
    "В зависимости от вида ограничения $q \\in Q$ возникают различные версии EM-алгоритма:\n",
    "* Точный EM-алгоритм. В нём $Q$ — множество всех вероятностных распределений. Этот пример уже разбирался в описании EM-алгоритма. Осталось лишь заметить, что на E-шаге при вычислении решения требуется взять интеграл $\\int p(X, Z \\, \\vert \\, \\theta^{(n)}) dZ$, но он может не браться. Проблема может возникнуть, если распределения $p(X \\, \\vert \\, Z, \\theta^{(n)})$ и $p(Z \\, \\vert \\, \\theta^{(n)})$ не образуют пару сопряжённых друг к другу. Поэтому иногда приходится брать как $Q$ нечто более узкое, чем множество всех вероятностных распределений, и проводить приближённые E-шаги.\n",
    "* Жёсткий (crisp) EM-алгоритм. В нём $Q$ — множество всех атомарных распределений, сконцентрированных в одной точке (в данном случае, в одной матрице): $Q = \\{\\delta(Z - Z_0) \\, \\vert \\, Z_0 \\in \\mathbb{R}^{l \\times h}\\}$, где $\\delta$ — дельта-функция Дирака. При таком ограничении E-шаг всегда можно провести: из определения дивергенции Кульбака-Лейблера получится, что решение — это распределение, сконцентрированное в точке моды по $Z$ распределения $p(Z \\, \\vert \\, X, \\theta^{(n)}))$. Говоря абстрактно, можно сказать, что в общем случае задача E-шага является задачей функциональной оптимизации (оптимум ищется по вероятностному распределению $q$), а такие задачи чаще всего не могут быть решены средствами современной математики, однако сужением $Q$ до параметрического семейства задачу можно свести к задаче оптимизации по вещественным параметрам (например, все элементы семейства атомарных распределений биективно сопоставляются координатам точки, где сконцентрирована вся масса).\n",
    "* Вариационный EM-алгоритм. В нём $Q$ — множество распределений, допускающих факторизацию по столбцам: $Q = \\{ q(Z)\\, \\vert \\, q(Z) = \\Pi_{j=1}^h q_j(z_{\\dot{}j})\\}$, где $q_j(z_{\\dot{}j})$ — некоторое распределение уже только одного вектора-столбца, представляющего $j$-ю скрытую переменную (на самом деле, можно ослабить ограничение, вместо отдельных столбцов перейдя к непересекающимся множествам столбцов). Заметим, что дельта-функция от матрицы раскладывается в произведение дельта-функций от своих столбцов, так что вариационный EM-алгоритм охватывает все варианты, доступные жёсткому EM-алгоритму. На E-шаге решение $q^{(n+1)}$ ищется с использованием вариационного подхода (покоординатного подъёма), и при соблюдении некоторых условий это решение можно найти.\n",
    "\n",
    "Наконец, отдельно стоит выделить байесовский EM-алгоритм, где $\\theta$ рассматривается как случайный вектор, имеющий своё собственное известное априорное распределение $p(\\theta)$, а оценить требуется апостериорные распределения $p(\\theta \\, \\vert \\, X)$ и $p(Z \\, \\vert \\, X, \\theta)$. Введение $p(\\theta)$ влечёт за собой то, что вместо $p(X, Z \\, \\vert \\, \\theta)$ в выкладках фигурирует $p(X, Z, \\theta) = p(X, Z \\, \\vert \\, \\theta) p(\\theta)$. E-шаг при этом не изменится, потому что $p(\\theta^{(n)})$ сократится из выражения для $p(Z \\, \\vert \\, X, \\theta^{(n)})$, а вот на M-шаге будет решаться следующая задача:\n",
    "$$\\mathbb{E}_{q^{(n)}} \\log p(X, Z, \\theta) \\to \\max_{\\theta}.$$\n",
    "Иными словами, на M-шаге по сравнению с версией без априорного распределения на $\\theta$ к оптимизируемому выражению просто добавится слагаемое $\\log p(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "постановка_задачи"
    ]
   },
   "source": [
    "## Задача управления на базе машинно-обученной модели\n",
    "\n",
    "Машинное обучение может использоваться для решения задачи предсказания, а может использоваться для решения задачи управления. Чтобы увидеть разницу между этими двумя задачами, набросаем общий сценарий и введём некоторое количество базовых сущностей (выделены курсивом). Итак, пусть машинно-обученная _модель_ возвращает предсказания, _пользователь_ модели, получив эти предсказания, принимает _решение_, связанное с каким-либо _процессом_, а конечный _результат_ для пользователя зависит как от его решения, так и от того, как пройдёт процесс. В рамках такого описания задача является задачей предсказания, если решение пользователя не способно повлиять на внутренние стороны процесса, и является задачей управления, если решение пользователя изменяет протекание процесса. Сценарий можно и расширить, допустив, что в задаче управления пользователь также может влиять на признаки объектов и выбирать, для объектов с какими признаками получать предсказания.\n",
    "\n",
    "Примером задачи предсказания является задача кредитного скоринга. Здесь модель по признакам заёмщика предсказывает вероятность того, что кредит будет возвращён, пользователем является банк, решением является выдавать или нет кредит какому-то конкретному заёмщику, а процессом является процесс выплаты кредита этим заёмщиком. Поскольку платежеспособность заёмщика не зависит от того, в каком банке он получит кредит на условиях, идентичных условиям, предложенным банком, это именно задача предсказания.\n",
    "\n",
    "Примером задачи управления является задача планирования промо-акций в розничных сетях. В одной из наиболее простых постановок рассматривается всего один товар, и модель по размеру скидки, прошлой истории продаж, дню недели, прогнозу погоды и некоторым другим факторам должна предсказать, сколько единиц товара купят завтра. Здесь пользователем модели является розничная сеть, решением является выставленная скидка, а процессом является поведение покупателей в магазине, а именно то, как они берут продвигаемый товар. Результатом становится валовая прибыль, то есть суммарное количество приобретённых единиц товара, умноженное на отпускную цену. Описанная задача не является задачей предсказания, потому что размер скидки напрямую влияет на покупательское поведение.\n",
    "\n",
    "В задачах управления качество предсказательной модели иногда бывает сложно оценить на реальных данных. Например, менеджеры, выбрав изначальную скидку и увидев, что весь запас товара разберут, могут решить уменьшить скидку, но если условия сервиса с моделью, которым они пользуются, предполагают ограничение на то, что запросов на предсказание может быть не более одного в день, то предсказание спроса для новой скидки уже не будет получено, и фактический спрос будет не с чем сравнивать.\n",
    "\n",
    "Однако обычно сценарий использования моделей для задачи управления другой. Предсказательная модель встраивается в функцию от управляемых и неуправляемых параметров, возвращаемое значение которой нужно оптимизировать по управляемым параметрам, соблюдая наложенные на них ограничения. Скажем, если в задаче планирования промо-акций предоставленная моделью функция $\\mathrm{predict}$ предсказывает спрос по размеру скидки, температуре воздуха и вчерашнему спросу, то оптимизируемая функция валовой прибыли имеет вид:\n",
    "$$f(\\mathrm{discount}, \\mathrm{temperature}, \\mathrm{lag}) = (\\mathrm{initial\\_price} - \\mathrm{discount}) * \\mathrm{predict}(\\mathrm{discount}, \\mathrm{temperature}, \\mathrm{lag}).$$\n",
    "Эту функцию требуется оптимизировать по $\\mathrm{discount} \\in [0; \\mathrm{initial\\_price}]$, и это дополнительная задача оптимизации по суррогатной модели. Модель названа суррогатной, потому что была оценена по данным, а не выведена на основании законов и/или правил, относящихся к предметной области.\n",
    "\n",
    "Задача управления на базе машинно-обученной модели имеет следующие нюансы:\n",
    "* Может присутствовать ограничение на используемые методы машинного обучения (например, ансамбли над решающими деревьями возвращают функцию $\\mathrm{predict}$, являющуюся кусочно-постоянной и потому имеющей неинформативный градиент);\n",
    "* Помимо ошибок, содержащихся в данных, и ошибок, вызываемых аппроксимацией целевой переменной, появляются ошибки оптимизации (скажем, вызванные локальными экстремумами), то есть нужно быть требовательнее к данным и стараться обеспечить запас качества модели;\n",
    "* Наличие предсказательной силы не гарантирует наличие причинно-следственных связей; в частности, к истинному влиянию управляемого параметра моделью может быть ошибочно приписано влияние пропущенных параметров, скоррелированных с этим управляемым параметром. В эконометрике такие явления называют эндогенностью. Как следствие же, модель нужно обучать не только ради точного предсказания целевой переменной, но и ради достоверной оценки влияния факторов на эту целевую переменную."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "байесовские_методы",
     "статистический_вывод"
    ]
   },
   "source": [
    "## Байесовский статистический вывод\n",
    "\n",
    "#### Задача статистического вывода\n",
    "\n",
    "Пусть даны следующие сущности:\n",
    "* выборка, то есть матрица объекты-признаки $X$, содержащая только наблюдаемые признаки объектов;\n",
    "* вероятностная модель, то есть аналитический вид совместного распределения $p(X, Z)$, где $Z$ — матрица со скрытыми признаками объектов.\n",
    "\n",
    "Комментарии по поводу того, что дано, таковы. Матрицы $X$ и $Z$ имеют одинаковое количество строк, но, разумеется, количество столбцов не обязано быть одинаковым. Плотность же вероятностного распределения дана именно для совокупности объектов (для матриц, где может быть более одной строки), а не для одного объекта, потому что объекты могут не быть независимы друг от друга: например, ими могут быть наблюдения элементов одной и той же последовательности с влиянием прошлого на будущее.\n",
    "\n",
    "Задача заключается в нахождении оценки $\\hat{Z}$ для неизвестной матрицы $Z$, соответствующей известной матрице $X$. Также задачу можно расширить до такой: найти апостериорное распределение $p(Z \\, \\vert \\, X)$, а не только точечную оценку $\\hat{Z}$.\n",
    "\n",
    "#### Байесовский подход к задаче статистического вывода\n",
    "\n",
    "При байесовском подходе предполагается, что $p(X, Z) = p(X \\, \\vert \\, Z) p(Z)$, где в аналитическом виде даны и $p(X \\, \\vert \\, Z)$, и $p(Z)$. При этом $p(X \\, \\vert \\, Z)$ называется правдоподобием выборки $X$ при условии $Z$, а $p(Z)$ является априорным распределением $Z$ (взятым на основании знаний о предметной области или полученным как апостериорное распределение $Z$ при условии какой-то ранее наблюдавшейся выборки $X_\\mathrm{old}$).\n",
    "\n",
    "Решение задачи, данной в байесовской постановке, описывается так:\n",
    "* Апостериорное распределение находится по теореме Байеса:\n",
    "$$p(Z \\, \\vert \\, X) = \\frac{p(X, Z)}{p(X)} = \\frac{p(X, Z)}{\\int p(X, Z) dZ},$$\n",
    "* Точечная оценка $\\hat{Z}$ получается как мода или как математическое ожидание полученного апостериорного распределения:\n",
    "    - $\\hat{Z} = \\arg \\max_Z p(Z \\, \\vert \\, X)$,\n",
    "    - $\\hat{Z} = \\mathbb{E}_{p(Z \\, \\vert \\, X)}[Z]$.\n",
    "    \n",
    "Основная сложность, связанная с байесовским статистическим выводом, как правило, заключается во взятии интеграла из знаменателя правой части формулы для апостериорного распределения.\n",
    "\n",
    "Дополнительно отметим ещё одну особенность байесовского взгляда на описанную задачу. В байесовской парадигме неизвестные параметры вероятностного распределения являются случайными величинами. Поэтому в качестве матрицы $Z$ можно брать матрицу параметров распределения, которые требуется оценить. Если параметры не могут меняться от наблюдения к наблюдению, необходимо наложить на $Z$ ограничение, что все строки являются одинаковыми, — такое ограничение закладывается в априорное распределение $Z$ и поэтому отдельно оно нигде не фигурирует. Формально это ограничение вводится так: от $p(Z)$ требуется быть нулевой для любой матрицы $Z$, у которой есть различающиеся строки. \n",
    "\n",
    "#### Способы решения задачи\n",
    "\n",
    "Существуют следующие способы найти апостериорное распределение $p(Z \\, \\vert \\, X)$:\n",
    "* Если это возможно, явно взять интеграл из знаменателя в выражении для апостериорного распределения. Данный подход примением, например, тогда, когда $Z$ принимает дискретные значения и интеграл, на самом деле, является суммой, или тогда, когда $p(X \\, \\vert \\, Z)$ и $p(Z)$ — пара сопряжённых (conjugate) распределений;\n",
    "* Вариационный байесовский вывод. Вводится предположение факторизуемости $p(X, Z)$ на непересекающиеся группы переменных, и на базе этого предположения проводится приближённое вычисление апостериорного распределения методом покоординатного подъёма;\n",
    "* Методы Монте-Карло по схеме марковской цепи, MCMC. Это численные методы взятия интеграла из знаменателя в выражении для апостериорного распределения, позволяющие сэмплировать значения $Z$ из распределения $p(Z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "байесовские_методы",
     "статистический_вывод"
    ]
   },
   "source": [
    "## Вариационный байесовский вывод\n",
    "\n",
    "#### Описание и обоснование\n",
    "\n",
    "Пусть рассматривается задача байесовского статистического вывода, где по матрице наблюдаемых переменных $X$ требуется найти апостериорное распределение матрицы скрытых переменных $p(Z \\, \\vert \\, X)$, имея явный вид вероятностной модели $p(X, Z) = p(X \\, \\vert \\, Z) p(Z)$, где оба множителя правой части даны аналитически.\n",
    "\n",
    "Вариационный байесовский вывод применяется в ситуации, когда апостериорное распределение $p(Z \\, \\vert \\, X) = \\frac{p(X, Z)}{p(X)} = \\frac{p(X, Z)}{\\int p(X, Z) dZ}$ не получается найти явно из-за того, что не вычисляется аналитически $p(X) = \\int p(X, Z) dZ$. Вместо искомого распределения $p(Z \\, \\vert \\, X)$ ищется его некоторое приближение $q(Z)$, тоже являющееся вероятностным распределением матрицы $Z$. Итак, цель заключается в том, чтобы найти $q(Z) \\approx p(Z \\, \\vert \\, X)$, где близость понимается в смысле минимизации дивергенции Кульбака-Лейблера между распределениями $q(Z)$ и $p(Z \\, \\vert \\, X)$:\n",
    "$$D_{KL}(q(Z) \\, \\Vert \\, p(Z \\, \\vert \\, X)) \\to \\min_{q},$$\n",
    "причём порядок аргументов дивергенции Кульбака-Лейблера такой, какой есть, потому что именно для такой дивергенции Кульбака-Лейблера удаётся найти решение сформулированной оптимизационной задачи.\n",
    "\n",
    "Для решения поставленной задачи сведём её к эквивалентной ей оптимизационной задаче.\n",
    "\n",
    "Каким бы ни было распределение $q(Z)$, всегда можно переписать логарифм правдоподобия наблюдаемой части выборки следующим образом:\n",
    "$$\\log p(X) = \\log p(X) \\int q(Z) dZ = \\int q(Z) \\log p(X) dZ = \\int q(Z) \\log \\frac{p(X, Z)}{p(Z \\, \\vert \\, X)} dZ = \\int q(Z) \\log \\frac{p(X, Z)q(Z)}{p(Z \\, \\vert \\, X)q(Z)} dZ \\\\ = \\int q(Z) \\log \\frac{p(X, Z)}{q(Z)} dZ + \\int q(Z) \\log \\frac{q(Z)}{p(Z \\, \\vert \\, X)} dZ.$$\n",
    "\n",
    "Обозначим первое слагаемое последнего выражения за $\\mathcal{L}(q)$ и заметим, что второе слагаемое является той самой дивергенцией Кульбака-Лейблера $D_{KL}(q(Z) \\, \\Vert \\, p(Z \\, \\vert \\, X))$, которую необходимо минимизировать. Значит,\n",
    "$$\\log p(X) = \\mathcal{L}(q) + D_{KL}(q(Z) \\, \\Vert \\, p(Z \\, \\vert \\, X)).$$\n",
    "\n",
    "Благодаря такому равенству можно взглянуть на поиск приближения $q(Z)$ для неизвестного распределения $p(Z \\, \\vert \\, X)$, которое, собственно говоря, неизвестно из-за невозможности вычислить $p(X)$, с двух точек зрения:\n",
    "* Исходная оптимизационная задача. Минимизацией $D_{KL}(q(Z) \\, \\Vert \\, p(Z \\, \\vert \\, X))$ по $q$ можно получить приближение для $p(Z \\, \\vert \\, X)$, потому что дивергенция Кульбака-Лейблера неотрицательна и, более того, обнуляется тогда и только тогда, когда два распределения идентичны.\n",
    "* Эквивалентная ей оптимизационная задача. Максимизацией $\\mathcal{L}(q)$ по $q$ можно получить приближение (а именно оценку снизу) для $p(X)$, потому что $\\mathcal{L}(q)$ не может быть больше $\\log p(X)$ в силу неотрицательности дивергенции Кульбака-Лейблера;\n",
    "\n",
    "Раз две выписанных оптимизационных задачи эквивалентны (имеют одинаковое решение), остановимся на второй:\n",
    "$$\\mathcal{L}(q) \\to \\max_{q}.$$\n",
    "Она выбрана, потому что удобнее для применения вариационного подхода.\n",
    "\n",
    "Заметим, что до сих пор не вводилось никаких дополнительных предположений по сравнению с теми, что есть в общей постановке задачи байесовского статистического вывода. Вовлечение вариационного подхода опирается на то, что на распределение $q$ накладывается ограничение факторизуемости. Оно означает, что существует такая разбивка столбцов матрицы $Z$ на $m$ непересекающихся множеств, что\n",
    "$$q(Z) = \\Pi_{i=1}^m q_i(Z_i),$$\n",
    "где $Z_i$ — матрица, получающаяся из матрицы $Z$ оставлением тех и только тех столбцов, которые попадают в $i$-е множество, а $q_i(Z_i)$ — произвольное распределение матрицы $Z_i$. Стало быть, теперь ищется приближение распределения $p(Z \\, \\vert \\, X)$ в классе факторизуемых вероятностных распределений.\n",
    "\n",
    "Будем решать оптимизационную задачу итеративно методом покоординатного подъёма. Инициализируем как-то все $q_i$, а затем на каждом шаге будем по очереди обновлять каждое из них в соответствии со следующим правилом:\n",
    "$$q_i(Z_i) := \\frac{\\exp(\\int \\log p(X, Z) \\Pi_{j \\ne i} q_j(Z_j) dZ_{-i})}{\\int \\exp(\\int \\log p(X, Z) \\Pi_{j \\ne i} q_j(Z_j) dZ_{-i}) dZ_i},$$\n",
    "где $Z_{-i}$ обозначает матрицу, получающуюся из $Z$ выкидыванием столбцов, принадлежащих $i$-му множеству. Выписанная формула обновления $q_i(Z_i)$ называется основной формулой вариационного байесовского вывода, а её получение здесь ради краткости опущено. Вывод же назван вариационным, потому что при оптимизации используется взятие вариации оптимизируемого функционала $\\mathcal{L}(q)$ вдоль направления, соответствующего $i$-му множеству скрытых переменных. \n",
    "\n",
    "Может показаться, что интеграл из знаменателя правой части основной формулы вариационного байесовского вывода ничуть не проще исходного интеграла из формулы для апостериорного распределения. Однако взять этот интеграл иногда удаётся. В следующем разделе будет описано, что и при каких условиях возможно.\n",
    "\n",
    "#### Применимость в зависимости от имеющихся свойств\n",
    "\n",
    "Чтобы описывать различные ситуации, введём ряд определений.\n",
    "\n",
    "Начнём с понятия условной сопряжённости, являющегося ослаблением понятия сопряжённости. Пусть матрица $Z$ факторизуется в разбивке своих столбцов на $m$ непересекающихся множеств. Примем за $\\{Z_i\\}_{i=1}^m$ множество из $m$ матриц, $i$-я из которых получается из $Z$ оставлением только соответствующих $i$-му множеству столбцов, а через $Z_{-i}$ обозначим матрицу, получающуюся из $Z$ выкидыванием всех столбцов, соответствующих $i$-му множеству. Будем говорить, что присутствует условная сопряжённость, если одновременно выполнены $m$ условий, $i$-е из которых имеет вид:\n",
    "* Для любого зафиксированного значения матрицы $Z_{-i}$ (то есть для любых зафиксированных значений всех матриц $Z_j$, где берутся все $j$ от 1 до $m$ кроме $i$), распределения $p(X \\, \\vert Z_i, Z_{-i})$ и $p(Z_i \\, \\vert Z_{-i})$ сопряжены друг к другу.\n",
    "\n",
    "Теперь предположим, что матрица $Z$ является боковой конкатенацией матриц $T$ и $\\Theta$, где $T$  матрица скрытых признаков объектов, а $\\Theta$ — матрица неизвестных параметров вероятностной модели. Будем считать, что $p(Z) = p(T, \\Theta) = p(T)p(\\Theta)$, то есть имеется факторизация при разбивке столбцов $Z$ на те, которые относятся к $T$, и на те, которые относятся к $\\Theta$.\n",
    "\n",
    "Определим $T$-сопряжённость как ослабление условной сопряжённости до того, что при факторизации в разбивке $Z$ на $T$ и $\\Theta$ условие выполнено только для $Z_i = T$, то есть как то, что пару сопряжённых распределений образуют $p(X \\, \\vert T, \\Theta)$ и $p(T \\, \\vert \\, \\Theta)$. Аналогично, определим $\\Theta$-сопряжённость как то, что сопряжены друг к другу распределения $p(X \\, \\vert \\Theta, T)$ и $p(\\Theta \\, \\vert \\, T)$.\n",
    "\n",
    "Далее, назовём условной $T$-сопряжённостью свойство, при котором $T$ сама как-то факторизуется и для факторизации всей $Z$ на $\\Theta$ и на то, на что разбивается $T$, есть условная сопряжённость, а условной $\\Theta$-сопряжённостью назовём свойство, при котором $\\Theta$ как-то факторизуется и для факторизации всей $Z$ на $T$ и на то, на что разбивается $\\Theta$, есть условная сопряжённость. \n",
    "\n",
    "В зависимости от присутствующего свойства применимы следующие методы статистического вывода:\n",
    "* сопряжённость (полная, т.е. $Z$-сопряжённость): полный байесовский вывод, без каких бы то ни было приближений оценивающий $p(Z \\, \\vert X) = p(T, \\Theta \\, \\vert \\, X)$;\n",
    "* условная сопряжённость в разбивке $Z$ на $T$ и $\\Theta$: вариационный байесовский вывод, оценивающий $q(Z) = q(T)q(\\Theta) \\approx p(T, \\Theta \\, \\vert \\, X)$;\n",
    "* $T$-сопряжённость: точный EM-алгоритм, являющийся частным случаем вариационного байесовского вывода, где дополнительно предполагается, что $q(\\Theta) = \\delta(\\Theta - \\Theta_0)$ и в этой записи $\\delta$ — дельта-функция Дирака, а $\\Theta_0$ — константная матрица, которую требуется найти; точный EM-алгоритм оценивает $q(Z) = q(T)\\delta(\\Theta - \\Theta_0) \\approx p(T, \\Theta \\, \\vert \\, X)$;\n",
    "* $\\Theta$-сопряжённость: точный ME-алгоритм, являющийся частным случаем вариационного байесовского вывода, где дополнительно предполагается, что $q(T) = \\delta(T - T_0)$, а $T_0$ — константная матрица, которую требуется найти; точный ME-алгоритм оценивает $q(Z) = \\delta(T - T_0)q(\\Theta) \\approx p(T, \\Theta \\, \\vert \\, X)$;\n",
    "* условная $T$-сопряжённость: вариационный EM-алгоритм, оценивающий $q(Z) = \\Pi_{i=1}^m q_i(T_i) \\, \\delta(\\Theta - \\Theta_0) \\approx p(T, \\Theta \\, \\vert \\, X)$;\n",
    "* условная $\\Theta$-сопряжённость: вариационный ME-алгоритм, оценивающий $q(Z) = \\delta(T - T_0) \\, \\Pi_{i=1}^m q_i(\\Theta_i)\\approx p(T, \\Theta \\, \\vert \\, X)$;\n",
    "* никаких свойств нет: жёсткий EM-алгоритм, оценивающий $q(Z) = \\delta(T - T_0) \\delta(\\Theta - \\Theta_0) \\approx p(T, \\Theta \\, \\vert \\, X)$, то есть дающий только точечные оценки.\n",
    "\n",
    "Получившийся список можно прокомментировать так. Чем более слабое свойство имеется, тем более \"простым\" распределением приходится полагать то распределение, которое ищется в задаче статистического вывода. \"Простота\" здесь понимается как факторизуемость.\n",
    "\n",
    "Напоследок разберём какой-нибудь пример, показывающий, почему указанных свойств достаточно для соответствующих методов. Скажем, остановимся на достаточности $T$-сопряжённости для точного EM-алгоритма. В точном EM-алгоритме сложное место находится на E-шаге, где ищется распределение $$q^{(n+1)}(Z) = p(Z \\, \\vert \\, X, \\Theta^{(n)}) = \\frac{p(X, Z \\, \\vert \\,  \\Theta^{(n)})}{\\int p(X, Z \\, \\vert \\, \\Theta^{(n)}) dZ} = \\frac{p(X \\, \\vert \\, Z, \\Theta^{(n)})p(Z \\, \\vert \\, \\Theta^{(n)})}{\\int p(X \\, \\vert \\, Z, \\Theta^{(n)})p(Z \\, \\vert \\, \\Theta^{(n)}) dZ} = \\frac{p(X \\, \\vert \\, T, \\Theta^{(n)})p(T \\, \\vert \\, \\Theta^{(n)})\\delta(\\Theta - \\Theta^{(n)})}{\\int p(X \\, \\vert \\, T, \\Theta^{(n)})p(T \\, \\vert \\, \\Theta^{(n)})\\delta(\\Theta - \\Theta^{(n)}) dT d\\Theta} = \\frac{p(X \\, \\vert \\, T, \\Theta^{(n)})p(T \\, \\vert \\, \\Theta^{(n)})}{\\int p(X \\, \\vert \\, T, \\Theta^{(n)})p(T \\, \\vert \\, \\Theta^{(n)}) dT} = \\frac{p(X, T \\, \\vert \\, \\Theta^{(n)})}{\\int p(X, T \\, \\vert \\, \\Theta^{(n)}) dT},$$\n",
    "и тут интеграл в полученном в конце выражении берётся явно в силу $T$-сопряжённости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "анализ_последовательностей",
     "графические_модели"
    ]
   },
   "source": [
    "## Скрытые марковские модели\n",
    "\n",
    "#### Введение\n",
    "\n",
    "Скрытая марковская модель с $m$ скрытыми состояниями и $n$ наблюдаемыми состояниями — это совокупность сущностей из следующего списка:\n",
    "* Вероятностное распределение $\\pi$ на множестве $\\{1, ..., m\\}$, представляющее собой распределение скрытого состояния в начальный момент времени;\n",
    "* Матрица переходов между скрытыми состояниями $A$, её размер $m \\times m$, а на пересечении $i$-й строки и $j$-го столбца стоит вероятность из скрытого состояния $i$ перейти в скрытое состояние $j$; как следствие сумма элементов любой строки матрицы $A$ равна 1;\n",
    "* Матрица эмиссии наблюдаемых значений $B$, её размер $m \\times n$, а на пересечении $i$-й строки и $j$-го столбца стоит условная вероятность того, что текущее наблюдаемое состояние равно $j$ при условии, что текущее скрытое состояние есть $i$.\n",
    "\n",
    "Для переноса на случай, когда наблюдаемые значения непрерывны, можно считать, что вместо матрицы $B$ имеются $m$ вероятностных распределений.\n",
    "\n",
    "В контексте скрытых марковских моделей существуют следующие задачи:\n",
    "* Зная $\\pi$, $A$ и $B$, вычислить вероятность данной последовательности наблюдаемых значений $\\{x_t\\}_{t=1}^l$, где $l$ — длина последовательности;\n",
    "* Зная $\\pi$, $A$ и $B$, по имеющейся последовательности наблюдаемых значений $\\{x_t\\}_{t=1}^l$ восстановить последовательность скрытых значений $\\{h_t\\}_{t=1}^l$;\n",
    "* Имея множество последовательностей наблюдаемых значений $\\left\\{\\{x_t\\}_{t=1}^{l_k} \\; \\vert \\; k \\in \\{1, ..., c\\}\\right\\}$, где $c$ — количество обучающих последовательностей, оценить $\\pi$, $A$ и $B$, то есть обучить скрытую марковскую модель.\n",
    "\n",
    "#### Задача вычисления вероятности наблюдаемой последовательности\n",
    "\n",
    "Эта задача является задачей вероятностного (прямого) вывода, а не задачей статистического (обратного) вывода. На самом деле, подсчитать искомую вероятность можно просто в лоб по определению скрытой марковской модели. Однако для повышения вычислительной эффективности используется алгоритм прохода вперёд (forward algorithm).\n",
    "\n",
    "#### Задача восстановления последовательности скрытых состояний\n",
    "\n",
    "Эта задача решается алгоритмом Витерби.\n",
    "\n",
    "#### Задача обучения скрытой марковской модели\n",
    "\n",
    "Данная задача решается алгоритмом Баума-Уэлша, являющимся частным случаем EM-алгоритма, применяемого во многих задачах обучения вероятностных графических моделей."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
