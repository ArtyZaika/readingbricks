## Способы автоматического обнаружения выбросов

Выброс (outlier) — объект, считающийся нетипичным для генеральной совокупности, фигурирующей в задаче. Выбросы могут искажать результаты обучения модели, а также результаты оценки качества модели (что создаёт риск неправильного подбора гиперпараметров). Строго говоря, является ли какой-то объект выбросом или нет, должен определять человек, отталкиваясь от своего понимания предметной области и от знаний о том, как именно собирались данные. Тем не менее на практике автоматическое удаление выбросов тоже может существенно улучшить конечный результат.

Способы обнаружения выбросов делятся на две группы в зависимости от того, на какие выбросы они реагируют:

1) Способы, позволяющие выявить одномерные выбросы, то есть выбросы, являющиеся аномальными значениями какого-либо одного признака. Пример одномерного выброса: среди точек на плоскости с координатами (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (100, 6) у последней точки подозрительно большая абсцисса.

2) Способы, позволяющие выявить многомерные выбросы, то есть выбросы, являющиеся аномальными объектами с точки зрения распределения данных. Пример многомерного выброса: среди точек на плоскости с координатами (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (1, 5) последняя точка лежит в стороне от прямой, на которой лежат все остальные точки, но при этом и её абсцисса, и её ордината не выбиваются из диапазона значений остальных точек.

К одномерным способам относятся:

* Стандартизированная оценка (Z-score) — из всех значений признака вычитается эмпирическое среднее этого признака, а полученные разности делятся на оценку стандартного отклонения признака; если получившееся отношение превышает 3, то объект считается выбросом. Порог 3 выбран, потому что в случае нормального распределения вероятность отклониться от среднего больше, чем на 3 стандартных отклонения, составляет 0,03% ([правило трёх сигм](https://ru.wikipedia.org/wiki/%D0%A1%D1%80%D0%B5%D0%B4%D0%BD%D0%B5%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BE%D1%82%D0%BA%D0%BB%D0%BE%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5#%D0%9F%D1%80%D0%B0%D0%B2%D0%B8%D0%BB%D0%BE_%D1%82%D1%80%D1%91%D1%85_%D1%81%D0%B8%D0%B3%D0%BC)). 

* Устойчивая стандартизированная оценка (robust Z-score) — то же самое, что и стандартизированная оценка, но теперь вычитается медиана, а не среднее, и разности делятся на средний модуль отклонения от медианы, а не на стандартное отклонение. Предпочтительнее в тех ситуациях, где выбросов достаточно много для того, чтобы они могли исказить среднее и стандартное отклонение так, что часть из них будет принята за обычные объекты.

* Метод межквартильного размаха (interquartile range method) — берётся расстояние между 0,75-й и 0,25-й квантилями (так называемый межквартильный размах), а затем выбросами объявляются все наблюдения, отстоящие от медианы более чем на 1,5 межквартильных размаха. Численные параметры приведены в соответствии с классическим вариантом, но, разумеется, их можно поменять (например, вместо двух квартилей взять две другие квантили).

К многомерным способам относятся:

* Способы, где для каждого объекта считается расстояние Махалонобиса от него до некоторого оценённого по данным распределения, принимаемого за генеральную совокупность, а потом некой одномерной процедурой выбросами объявляются сколько-то объектов с наибольшим расстоянием Махалонобиса. Рассмотрим такой подход подробнее. Для многомерного вектора $x$ и многомерного вероятностного распределения $\tau(\mu, S)$ с вектором средних $\mu$ и ковариационной матрицей $S$ "расстоянием" от $x$ до $\tau(\mu, S)$ можно положить величину:
$$D_M(x, \tau(\mu, S)) = \sqrt{(x - \mu)^T S^{-1} (x - \mu)},$$
которая и называется расстоянием Махалонобиса. Интуитивно говоря, расстояние Махалонобиса отличается от евклидова расстояния между $x$ и $\mu$ тем, что каждое направление учитывается с весом, обратно пропорциональным разбросу распределения по этому направлению. В задаче обнаружения выбросов $\tau(\mu, S))$ можно единожды оценить по всем имеющимся данным, если их много, или же для каждого $x$ оценивать по всем объектам кроме $x$, если данных мало.

* Способы, где для каждого объекта считается оценка плотности генеральной совокупности в нём, а затем некой одномерной процедурой выбросами объявляются сколько-то объектов с наиболее низкой оценкой плотности. Оценку плотности можно получить, в частности, методом ядреного сглаживания (kernel density estimate). Как и в предыдущем пункте, если данных мало, то оценку ядерного сглаживания для каждого объекта лучше считать по всем объектам кроме него, а если данных много, то оценку ядерного сглаживания можно подсчитать один раз на всех объектах. Отдельно стоит отметить, что оценки ядерного сглаживания подвержены "проклятью размерности" и работают только в случае, когда размерность данных низкая. Если же размерность высокая, то для применения ядерного сглаживания можно предварительно снизить её, использовав PCA, t-SNE или MDS на отмасштабированных данных, однако как проводить масштабирование — нетривиальный вопрос, вносящий долю субъективности. 
